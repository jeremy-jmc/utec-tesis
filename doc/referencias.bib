@article{Temsah2025DeepSeek,
  title   = {DeepSeek in Healthcare: Revealing Opportunities and Steering Challenges of a New Open-Source Artificial Intelligence Frontier},
  author  = {Temsah, A. and Alhasan, K. and Altamimi, I. and Jamal, A. and Al-Eyadhy, A.},
  journal = {Cureus},
  year    = {2025},
  volume  = {17},
  number  = {2},
  pages   = {e341667},
  doi     = {10.7759/cureus.341667},
  url     = {https://www.cureus.com/articles/341667-deepseek-in-healthcare-revealing-opportunities-and-steering-challenges-of-a-new-open-source-artificial-intelligence-frontier.pdf}
}

@misc{Jiang2024UrbanLLM,
  title         = {UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models},
  author        = {Yue Jiang and Qin Chao and Yile Chen and Xiucheng Li and Shuai Liu and Gao Cong},
  year          = {2024},
  eprint        = {2406.12360},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2406.12360}
}

@misc{Li2024UrbanGPT,
  title         = {UrbanGPT: Spatio-Temporal Large Language Models},
  author        = {Zhonghang Li and Lianghao Xia and Jiabin Tang and Yong Xu and Lei Shi and Long Xia and Dawei Yin and Chao Huang},
  year          = {2024},
  eprint        = {2403.00813},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2403.00813}
}

@misc{Deng2025VisualChronicles,
  title         = {Visual Chronicles: Using Multimodal LLMs to Analyze Massive Collections of Images},
  author        = {Boyang Deng and Songyou Peng and Kyle Genova and Gordon Wetzstein and Noah Snavely and Leonidas Guibas and Thomas Funkhouser},
  year          = {2025},
  eprint        = {2504.08727},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2504.08727}
}

@misc{Zhang2023GeoGPT,
  title         = {GeoGPT: Understanding and Processing Geospatial Tasks through An Autonomous GPT},
  author        = {Yifan Zhang and Cheng Wei and Shangyou Wu and Zhengting He and Wenhao Yu},
  year          = {2023},
  eprint        = {2307.07930},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2307.07930}
}

@misc{He2024GRetriever,
  title         = {G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering},
  author        = {Xiaoxin He and Yijun Tian and Yifei Sun and Nitesh V. Chawla and Thomas Laurent and Yann LeCun and Xavier Bresson and Bryan Hooi},
  year          = {2024},
  eprint        = {2402.07630},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.07630}
}

@misc{Dai2024QASTKG,
  title         = {Question Answering Over Spatio-Temporal Knowledge Graph},
  author        = {Xinbang Dai and Huiying Li and Guilin Qi},
  year          = {2024},
  eprint        = {2402.11542},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.11542}
}


@inproceedings{Saxena2021TemporalKGQA,
  title     = {Question Answering Over Temporal Knowledge Graphs},
  author    = {Saxena, Apoorv  and Chakrabarti, Soumen and Talukdar, Partha},
  editor    = {Zong, Chengqing  and Xia, Fei  and Li, Wenjie  and Navigli, Roberto},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.520/},
  doi       = {10.18653/v1/2021.acl-long.520},
  pages     = {6663--6676},
  abstract  = {Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broad coverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340x. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformer-based solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120{\%} in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well.}
}

@misc{Perozzi2024GraphToken,
  title         = {Let Your Graph Do the Talking: Encoding Structured Data for LLMs},
  author        = {Bryan Perozzi and Bahare Fatemi and Dustin Zelle and Anton Tsitsulin and Mehran Kazemi and Rami Al-Rfou and Jonathan Halcrow},
  year          = {2024},
  eprint        = {2402.05862},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.05862}
}


@misc{Fatemi2023GraphEncoding,
  title         = {Talk like a Graph: Encoding Graphs for Large Language Models},
  author        = {Bahare Fatemi and Jonathan Halcrow and Bryan Perozzi},
  year          = {2023},
  eprint        = {2310.04560},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2310.04560}
}

@article{Zhang2025CrimeDatasetChina,
  author   = {Yan Zhang and Mei-Po Kwan and Libo Fang},
  title    = {An LLM driven dataset on the spatiotemporal distributions of street and neighborhood crime in China},
  journal  = {Scientific Data},
  volume   = {12},
  number   = {1},
  pages    = {467},
  year     = {2025},
  month    = {mar},
  doi      = {10.1038/s41597-025-04757-8},
  url      = {https://doi.org/10.1038/s41597-025-04757-8},
  issn     = {2052-4463},
  abstract = {Crime is a significant social, economic, and legal issue. This research presents an open-access spatiotemporal repository of street and neighborhood crime data, comprising approximately one million records of crimes in China, with specific geographic coordinates (latitude and longitude) and timestamps for each incident. The dataset is based on publicly available law court judgment documents. Artificial intelligence (AI) technologies are employed to extract crime events at the neighborhood or even building level from vast amounts of unstructured judicial text. This dataset enables more precise spatial analysis of crime incidents, offering valuable insights across interdisciplinary fields such as economics, sociology, and geography. It contributes significantly to the achievement of the United Nations Sustainable Development Goals (SDGs), particularly in fostering sustainable cities and communities, and plays a crucial role in advancing efforts to reduce all forms of violence and related mortality rates.}
}

@misc{NYCDataset,
  title        = {NYPD Complaint Data Historic},
  author       = {New York City Police Department},
  year         = {2025},
  howpublished = {\url{https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qb7u-rbmr}}
}

@misc{ChicagoDataset,
  title        = {Crimes - 2001 to Present},
  author       = {Chicago Police Department},
  year         = {2024},
  howpublished = {\url{https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2}}
}

@article{Garcia2022CriPAV,
  author   = {García-Zanabria, Germain and Raimundo, Marcos M. and Poco, Jorge and Nery, Marcelo Batista and Silva, Cláudio T. and Adorno, Sergio and Nonato, Luis Gustavo},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  title    = {CriPAV: Street-Level Crime Patterns Analysis and Visualization},
  year     = {2022},
  volume   = {28},
  number   = {12},
  pages    = {4000-4015},
  abstract = {Extracting and analyzing crime patterns in big cities is a challenging spatiotemporal problem. The hardness of the problem is linked to two main factors, the sparse nature of the crime activity and its spread in large spatial areas. Sparseness hampers most time series (crime time series) comparison methods from working properly, while the handling of large urban areas tends to render the computational costs of such methods impractical. Visualizing different patterns hidden in crime time series data is another issue in this context, mainly due to the number of patterns that can show up in the time series analysis. In this article, we present a new methodology to deal with the issues above, enabling the analysis of spatiotemporal crime patterns in a street-level of detail. Our approach is made up of two main components designed to handle the spatial sparsity and spreading of crimes in large areas of the city. The first component relies on a stochastic mechanism from which one can visually analyze probable×intensive crime hotspots. Such analysis reveals important patterns that can not be observed in the typical intensity-based hotspot visualization. The second component builds upon a deep learning mechanism to embed crime time series in Cartesian space. From the embedding, one can identify spatial locations where the crime time series have similar behavior. The two components have been integrated into a web-based analytical tool called CriPAV (Crime Pattern Analysis and Visualization), which enables global as well as a street-level view of crime patterns. Developed in close collaboration with domain experts, CriPAV has been validated through a set of case studies with real crime data in São Paulo - Brazil. The provided experiments and case studies reveal the effectiveness of CriPAV in identifying patterns such as locations where crimes are not intense but highly probable to occur as well as locations that are far apart from each other but bear similar crime patterns.},
  keywords = {Data visualization;Time series analysis;Urban areas;Spatiotemporal phenomena;Stochastic processes;Deep learning;Visual analytics;Criminal law;Crime data;spatio-temporal data;visual analytics;crime hotspots;stochastic matrix},
  doi      = {10.1109/TVCG.2021.3111146},
  issn     = {1941-0506},
  month    = {Dec}
}

@article{Garcia2020MiranteAV,
  title   = {Mirante: A visualization tool for analyzing urban crimes},
  author  = {Germain Garcia Zanabria and Erick Gomez Nieto and Jaqueline Silveira and Jorge Poco and Marcelo Batista Nery and Sergio Adorno and Luis Gustavo Nonato},
  journal = {2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},
  year    = {2020},
  pages   = {148-155},
  url     = {https://api.semanticscholar.org/CorpusID:227221852}
}

@article{Garcia2021CrimAnalyzer,
  title     = {CrimAnalyzer: Understanding Crime Patterns in São Paulo},
  volume    = {27},
  issn      = {2160-9306},
  url       = {http://dx.doi.org/10.1109/TVCG.2019.2947515},
  doi       = {10.1109/tvcg.2019.2947515},
  number    = {4},
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Garcia, Germain and Silveira, Jaqueline and Poco, Jorge and Paiva, Afonso and Nery, Marcelo Batista and Silva, Claudio T. and Adorno, Sergio and Nonato, Luis Gustavo},
  year      = {2021},
  month     = apr,
  pages     = {2313-2328}
}

@misc{Liu2024NLDriven,
  title         = {Breathing New Life into Existing Visualizations: A Natural Language-Driven Manipulation Framework},
  author        = {Can Liu and Jiacheng Yu and Yuhan Guo and Jiayi Zhuang and Yuchu Luo and Xiaoru Yuan},
  year          = {2024},
  eprint        = {2404.06039},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2404.06039}
}

@article{Wu2024LLMVis,
  author     = {Wu, Yang and Wan, Yao and Zhang, Hongyu and Sui, Yulei and Wei, Wucai and Zhao, Wei and Xu, Guandong and Jin, Hai},
  title      = {Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study},
  year       = {2024},
  issue_date = {June 2024},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {2},
  number     = {3},
  url        = {https://doi.org/10.1145/3654992},
  doi        = {10.1145/3654992},
  abstract   = {The Natural Language to Visualization (NL2Vis) task aims to transform natural-language descriptions into visual representations for a grounded table, enabling users to gain insights from vast amounts of data. Recently, many deep learning-based approaches have been developed for NL2Vis. Despite the considerable efforts made by these approaches, challenges persist in visualizing data sourced from unseen databases or spanning multiple tables. Taking inspiration from the remarkable generation capabilities of Large Language Models (LLMs), this paper conducts an empirical study to evaluate their potential in generating visualizations, and explore the effectiveness of in-context learning prompts for enhancing this task. In particular, we first explore the ways of transforming structured tabular data into sequential text prompts, as to feed them into LLMs and analyze which table content contributes most to the NL2Vis. Our findings suggest that transforming structured tabular data into programs is effective, and it is essential to consider the table schema when formulating prompts. Furthermore, we evaluate two types of LLMs: finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5), against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench). The experimental results reveal that LLMs outperform baselines, with inference-only models consistently exhibiting performance improvements, at times even surpassing fine-tuned models when provided with certain few-shot demonstrations through in-context learning. Finally, we analyze when the LLMs fail in NL2Vis, and propose to iteratively update the results using strategies such as chain-of-thought, role-playing, and code-interpreter. The experimental results confirm the efficacy of iterative updates and hold great potential for future study.},
  journal    = {Proc. ACM Manag. Data},
  month      = may,
  articleno  = {115},
  numpages   = {28},
  keywords   = {code generation, data analysis, data visualization, exploratory study, large language models, natural language processing}
}

@article{Luo2022NL2Vis,
  author   = {Luo, Yuyu and Tang, Nan and Li, Guoliang and Tang, Jiawei and Chai, Chengliang and Qin, Xuedi},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  title    = {Natural Language to Visualization by Neural Machine Translation},
  year     = {2022},
  volume   = {28},
  number   = {1},
  pages    = {217-226},
  keywords = {Data visualization;Natural languages;Bars;Deep learning;Machine translation;Visualization;Transformers;Natural language interface;data visualization;neural machine translation;chart template},
  doi      = {10.1109/TVCG.2021.3114848}
}


@article{Narechania2021NL4DV,
  title     = {NL4DV: A Toolkit for Generating Analytic Specifications for Data Visualization from Natural Language Queries},
  volume    = {27},
  issn      = {2160-9306},
  url       = {http://dx.doi.org/10.1109/TVCG.2020.3030378},
  doi       = {10.1109/tvcg.2020.3030378},
  number    = {2},
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Narechania, Arpit and Srinivasan, Arjun and Stasko, John},
  year      = {2021},
  month     = feb,
  pages     = {369-379}
}

@inproceedings{Liu2021ADVISor,
  author    = {Liu, Can and Han, Yun and Jiang, Ruike and Yuan, Xiaoru},
  booktitle = {2021 IEEE 14th Pacific Visualization Symposium (PacificVis)},
  title     = {ADVISor: Automatic Visualization Answer for Natural-Language Question on Tabular Data},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {11-20},
  keywords  = {Annotations;Natural languages;Pipelines;Neural networks;Data visualization;Tools;Data mining;Question answering;natural language;visualization;annotation;tabular data;machine learning;deep learning},
  doi       = {10.1109/PacificVis52677.2021.00010}
}

@inproceedings{Setlur2016Eviza,
  author    = {Setlur, Vidya and Battersby, Sarah E. and Tory, Melanie and Gossweiler, Rich and Chang, Angel X.},
  title     = {Eviza: A Natural Language Interface for Visual Analysis},
  year      = {2016},
  isbn      = {9781450341899},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2984511.2984588},
  doi       = {10.1145/2984511.2984588},
  abstract  = {Natural language interfaces for visualizations have emerged as a promising new way of interacting with data and performing analytics. Many of these systems have fundamental limitations. Most return minimally interactive visualizations in response to queries and often require experts to perform modeling for a set of predicted user queries before the systems are effective. Eviza provides a natural language interface for an interactive query dialog with an existing visualization rather than starting from a blank sheet and asking closed-ended questions that return a single text answer or static visualization. The system employs a probabilistic grammar based approach with predefined rules that are dynamically updated based on the data from the visualization, as opposed to computationally intensive deep learning or knowledge based approaches.The result of an interaction is a change to the view (e.g., filtering, navigation, selection) providing graphical answers and ambiguity widgets to handle ambiguous queries and system defaults. There is also rich domain awareness of time, space, and quantitative reasoning built in, and linking into existing knowledge bases for additional semantics. Eviza also supports pragmatics and exploring multi-modal interactions to help enhance the expressiveness of how users can ask questions about their data during the flow of visual analysis.},
  booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
  pages     = {365-377},
  numpages  = {13},
  keywords  = {visualization, visual data analysis, probabilistic grammar, pragmatics, parser, natural language, ambiguity},
  location  = {Tokyo, Japan},
  series    = {UIST '16}
}

@article{Salah2022BigCDVis,
  title   = {Big Crime Data Analytics and Visualization},
  author  = {Mokhtar Mansour Salah and Ke-wen Xia},
  journal = {Proceedings of the 2022 6th International Conference on Compute and Data Analysis},
  year    = {2022},
  url     = {https://api.semanticscholar.org/CorpusID:248990234}
}

@inproceedings{Silva2017CrimeVisAI,
  title     = {CrimeVis: An Interactive Visualization System for Analyzing Crime Data in the State of Rio de Janeiro},
  author    = {Luiz Jos{\'e} Schirmer Silva and Sonia Fiol-Gonz{\'a}lez and Cassio F. P. Almeida and Simone Diniz Junqueira Barbosa and H{\'e}lio C{\^o}rtes Vieira Lopes},
  booktitle = {International Conference on Enterprise Information Systems},
  year      = {2017},
  url       = {https://api.semanticscholar.org/CorpusID:46819581}
}

@inproceedings{Almuhanna2021CrimeNYC,
  author    = {Almuhanna, Abrar A. and Alrehili, Marwa M. and Alsubhi, Samah H. and Syed, Liyakathunisa},
  booktitle = {2021 1st International Conference on Artificial Intelligence and Data Analytics (CAIDA)},
  title     = {Prediction of Crime in Neighbourhoods of New York City using Spatial Data Analysis},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {23-30},
  keywords  = {Support vector machines;Deep learning;Radio frequency;Data analysis;Law enforcement;Urban areas;Data visualization;Spatio-temporal patterns;Crime;Neighbourhoods Prediction;Data Visualization;SVM;Random Forest;XGboost},
  doi       = {10.1109/CAIDA51941.2021.9425120}
}

@article{Ersoz2025CrimePredictionXAISurvey,
  author   = {Ersöz, Filiz and Ersöz, Taner and Marcelloni, Francesco and Ruffini, Fabrizio},
  journal  = {IEEE Access},
  title    = {Artificial Intelligence in Crime Prediction: A Survey With a Focus on Explainability},
  year     = {2025},
  volume   = {13},
  number   = {},
  pages    = {59646-59674},
  keywords = {Artificial intelligence;Law enforcement;Predictive models;Accuracy;Explainable AI;Reviews;Prevention and mitigation;Ethics;Surveys;Market research;Crime prediction;artificial intelligence;explainability;interpretability;crime datasets;survey},
  doi      = {10.1109/ACCESS.2025.3553934}
}


@misc{Utsha2024DLCrimeAnalysis,
  title         = {Deep Learning Based Crime Prediction Models: Experiments and Analysis},
  author        = {Rittik Basak Utsha and Muhtasim Noor Alif and Yeasir Rayhan and Tanzima Hashem and Mohammad Eunus Ali},
  year          = {2024},
  eprint        = {2407.19324},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2407.19324}
}


@misc{Yu2025SpatialRAG,
  title         = {Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions},
  author        = {Dazhou Yu and Riyang Bao and Gengchen Mai and Liang Zhao},
  year          = {2025},
  eprint        = {2502.18470},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2502.18470}
}

@misc{Hu2024GRAG,
  title         = {GRAG: Graph Retrieval-Augmented Generation},
  author        = {Yuntong Hu and Zhihan Lei and Zheng Zhang and Bo Pan and Chen Ling and Liang Zhao},
  year          = {2024},
  eprint        = {2405.16506},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2405.16506}
}


@misc{Edge2025GraphRAG,
  title         = {From Local to Global: A Graph RAG Approach to Query-Focused Summarization},
  author        = {Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Dasha Metropolitansky and Robert Osazuwa Ness and Jonathan Larson},
  year          = {2025},
  eprint        = {2404.16130},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2404.16130}
}
@misc{Guo2024LightRAG,
  title         = {LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author        = {Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year          = {2024},
  eprint        = {2410.05779},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2410.05779}
}

@misc{Xiao2024TimeRAG,
  title  = {Time{RAG}: It's Time for Retrieval-Augmented Generation in Time-Series Forecasting},
  author = {Mengxi Xiao and Zihao Jiang and Zhengyu Chen and Dong Li and Shuai Chen and Sophia Ananiadou and Jimin Huang and Min Peng and Qianqian Xie},
  year   = {2024},
  url    = {https://openreview.net/forum?id=GvzL4LuycW}
}

@misc{Yang2024TimeRAG,
  title         = {TimeRAG: BOOSTING LLM Time Series Forecasting via Retrieval-Augmented Generation},
  author        = {Silin Yang and Dong Wang and Haoqi Zheng and Ruochun Jin},
  year          = {2024},
  eprint        = {2412.16643},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2412.16643}
}

@inproceedings{Xu2024RAGKG,
  series     = {SIGIR 2024},
  title      = {Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering},
  url        = {http://dx.doi.org/10.1145/3626772.3661370},
  doi        = {10.1145/3626772.3661370},
  booktitle  = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  publisher  = {ACM},
  author     = {Xu, Zhentao and Cruz, Mark Jerome and Guevara, Matthew and Wang, Tie and Deshpande, Manasi and Wang, Xiaofeng and Li, Zheng},
  year       = {2024},
  month      = jul,
  pages      = {2905-2909},
  collection = {SIGIR 2024}
}

@inproceedings{Chen2025KGRAGSurvey,
  title     = {Retrieval-Augmented Generation with Knowledge Graphs: A Survey},
  author    = {Chen, Ruixi},
  year      = {2025},
  booktitle = {Computer Science Undergradaute Conference 2025@ XJTU}
}


@article{Pappula2023LLMsFC,
  title   = {LLMs for Conversational AI: Enhancing Chatbots and Virtual Assistants},
  author  = {Sharmila Reddy Pappula and Sathwik Rao Allam},
  journal = {International Journal of Research Publication and Reviews},
  year    = {2023},
  url     = {https://api.semanticscholar.org/CorpusID:266461220}
}



@article{Machado2012CrimeRJ,
  title   = {Medo Social e Turismo no Rio de Janeiro},
  author  = {Marcello de Barros Tom{\'e} Machado},
  journal = {Tourism \& Management Studies},
  year    = {2012},
  pages   = {48-54},
  url     = {https://api.semanticscholar.org/CorpusID:155721043}
}


@article{SopikoTevdoradze2024CrimeTourism,
  title   = {The Effect of Criminal Activity on Tourism},
  author  = {Sopiko Tevdoradze Sopiko Tevdoradze and Zurab Mushkudiani Zurab Mushkudiani and Nugzar Tevdoradze Nugzar Tevdoradze},
  journal = {The New Economist},
  year    = {2024},
  url     = {https://api.semanticscholar.org/CorpusID:273525446}
}

@misc{Contractor2020QATourism,
  title         = {Large Scale Question Answering using Tourism Data},
  author        = {Danish Contractor and Krunal Shah and Aditi Partap and Mausam and Parag Singla},
  year          = {2020},
  eprint        = {1909.03527},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1909.03527}
}

@misc{Wei2024TourLLM,
  title         = {TourLLM: Enhancing LLMs with Tourism Knowledge},
  author        = {Qikai Wei and Mingzhi Yang and Jinqiang Wang and Wenwei Mao and Jiabo Xu and Huansheng Ning},
  year          = {2024},
  eprint        = {2407.12791},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2407.12791}
}

@article{Zengli2020CrimePatterns,
  author         = {Wang, Zengli and Zhang, Hong},
  title          = {Construction, Detection, and Interpretation of Crime Patterns over Space and Time},
  journal        = {ISPRS International Journal of Geo-Information},
  volume         = {9},
  year           = {2020},
  number         = {6},
  article_number = {339},
  url            = {https://www.mdpi.com/2220-9964/9/6/339},
  issn           = {2220-9964},
  abstract       = {Empirical studies have focused on investigating the interactive relationships between crime pairs. However, many other types of crime patterns have not been extensively investigated. In this paper, we introduce three basic crime patterns in four combinations. Based on graph theory, the subgraphs for each pattern were constructed and analyzed using criminology theories. A Monte Carlo simulation was conducted to examine the significance of these patterns. Crime patterns were statistically significant and generated different levels of crime risk. Compared to the classical patterns, combined patterns create much higher risk levels. Among these patterns, “co-occurrence, repeat, and shift” generated the highest level of crime risk, while “repeat” generated much lower levels of crime risk. “Co-occurrence and shift” and “repeat and shift” showed undulated risk levels, while others showed a continuous decrease. These results outline the importance of proposed crime patterns and call for differentiated crime prevention strategies. This method can be extended to other research areas that use point events as research objects.},
  doi            = {10.3390/ijgi9060339}
}


@misc{vaswani2023attentionneed,
  title         = {Attention Is All You Need},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year          = {2023},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1706.03762}
}

@misc{RAG2021,
  title         = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author        = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  year          = {2021},
  eprint        = {2005.11401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.11401}
}

@misc{modularRAG2024,
  title         = {Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks},
  author        = {Yunfan Gao and Yun Xiong and Meng Wang and Haofen Wang},
  year          = {2024},
  eprint        = {2407.21059},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2407.21059}
}

@misc{chainofthought2023,
  title         = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author        = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year          = {2023},
  eprint        = {2201.11903},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2201.11903}
}


@article{Yang2024HumanAIInteraction,
  title   = {Human-AI Interaction in the Age of LLMs},
  author  = {Diyi Yang and Sherry Tongshuang Wu and Marti A. Hearst},
  journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 5: Tutorial Abstracts)},
  year    = {2024},
  url     = {https://api.semanticscholar.org/CorpusID:270514463}
}


@inproceedings{Waqar2025CrimePredictionGNN,
  author    = {Hassan, Waqar and Cabral, Marvin Mendes and Ramos, Thiago Rodrigo and Filho, Antonio Castelo and Nonato, Luis Gustavo},
  editor    = {Paes, Aline and Verri, Filipe A. N.},
  title     = {Modeling and Predicting Crimes in the City of Sao Paulo Using Graph Neural Networks},
  booktitle = {Intelligent Systems},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {372--386},
  abstract  = {Crime prediction is a critical research area for enhancing public safety and optimizing law enforcement resource allocation, and machine learning techniques have had a significant impact in this field. Traditional machine learning models have long struggled to capture complex crime patterns, primarily due to the intricate interdependence of spatial and temporal data. However, recent advancements in machine learning, particularly with Graph Neural Networks (GNNs), offer a new perspective. GNNs have demonstrated remarkable success in various applications and they can also play a significant role in crime analysis and prediction. Therefore, in this work, we explore such a potential by examining two distinct spatiotemporal GNN architectures, namely Dynamic Self-Attention Network (DySAT) and Evolving Graph Convolutional Network (EvolveGCN), assessing and comparing their effectiveness for crime prediction. Moreover, we propose a data modeling framework that integrates crime, street map graphs, and urban data, which is fundamental to properly train the GNN models. As far as we know, there is no consolidated methodology to integrate those three modalities of data, being a relevant contribution of this work. Our findings underscore the effectiveness of GNNs in crime prediction tasks, offering valuable insights for researchers and practitioners in the field of crime prevention and public safety enhancement.},
  isbn      = {978-3-031-79035-5}
}


@misc{2025GoogleGeospatialReasoning,
  author       = {Schottlander, David and Shekel, Tomer},
  title        = {Geospatial Reasoning: Unlocking insights with generative AI and multiple foundation models},
  howpublished = {Google Research Blog},
  month        = apr,
  year         = {2025},
  note         = {Available at: \url{https://research.google/blog/geospatial-reasoning-unlocking-insights-with-generative-ai-and-multiple-foundation-models/} (Accessed: 2025-04-18)}
}


@misc{Qwen2025Qwen2.5,
  title         = {Qwen2.5 Technical Report},
  author        = {Qwen and others},
  year          = {2025},
  eprint        = {2412.15115},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2412.15115}
}

@misc{Hui2024Qwen25Coder,
  title         = {Qwen2.5-Coder Technical Report},
  author        = {Binyuan Hui and Jian Yang and Zeyu Cui and Jiaxi Yang and Dayiheng Liu and Lei Zhang and Tianyu Liu and Jiajun Zhang and Bowen Yu and Keming Lu and Kai Dang and Yang Fan and Yichang Zhang and An Yang and Rui Men and Fei Huang and Bo Zheng and Yibo Miao and Shanghaoran Quan and Yunlong Feng and Xingzhang Ren and Xuancheng Ren and Jingren Zhou and Junyang Lin},
  year          = {2024},
  eprint        = {2409.12186},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2409.12186}
}


@misc{Grattafiori2024Llama3,
  title         = {The Llama 3 Herd of Models},
  author        = {Aaron Grattafiori et al.},
  year          = {2024},
  eprint        = {2407.21783},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2407.21783}
}


@misc{Roziere2024CodeLlama,
  title         = {Code Llama: Open Foundation Models for Code},
  author        = {Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Romain Sauvestre and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
  year          = {2024},
  eprint        = {2308.12950},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2308.12950}
}

@misc{Nvidia2024KaggleMath,
  author = {{NVIDIA Blog Team}},
  title  = {How AI Reasoning Is Being Tested with International Math Olympiad Problems},
  year   = {2024},
  url    = {https://blogs.nvidia.com/blog/reasoning-ai-math-olympiad/},
  note   = {Accessed: 2025-04-20}
}

@misc{Fleureau2024NuminaMath,
  author       = {Fleureau, Yann and Li, Jia and Beeching, Edward and 
                  Tunstall, Lewis and Lipkin, Ben and Soletskyi, Roman and 
                  Costa Huang, Shengyi and Rasul, Kashif},
  title        = {How NuminaMath Won the 1st AIMO Progress Prize},
  year         = {2024},
  month        = {jul},
  day          = {11},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/blog/winning-aimo-progress-prize}},
  note         = {Blog post, consultado el 6 de mayo de 2025}
}

@techreport{Li2024NuminaMath,
  title       = {NuminaMath: The largest public dataset in AI4Maths with 860k pairs of competition math problems and solutions},
  author      = {Jia Li and Edward Beeching and Lewis Tunstall and Ben Lipkin and Roman Soletskyi and Shengyi Huang and Kashif Rasul and Longhui Yu and Albert Q. Jiang and Ziju Shen and Zihan Qin and Bin Dong and Li Zhou and Yann Fleureau and Guillaume Lample and Stanislas Polu},
  institution = {Numina, Hugging Face, MIT, Mistral AI, Peking University, Answer AI},
  year        = {2024},
  month       = {July},
  url         = {https://github.com/project-numina/aimo-progress-prize/blob/main/report/numina_dataset.pdf},
  note        = {Winner of the 1st AIMO Progress Prize}
}

@misc{Wang2023SelfConsistency,
  title         = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author        = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
  year          = {2023},
  eprint        = {2203.11171},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2203.11171}
}

@misc{Yin2024MuMathCode,
  title         = {MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning},
  author        = {Shuo Yin and Weihao You and Zhilong Ji and Guoqiang Zhong and Jinfeng Bai},
  year          = {2024},
  eprint        = {2405.07551},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2405.07551}
}


@misc{Jain2024MetaFineTuning,
  author       = {Jain, Aditya and Maleki, Amir and Saade, Nathalie},
  title        = {How to fine-tune: Focus on effective datasets},
  year         = {2024},
  month        = {aug},
  day          = {7},
  publisher    = {Meta AI},
  howpublished = {\url{https://ai.meta.com/blog/how-to-fine-tune-llms-peft-dataset-curation/}},
  note         = {Blog post, consultado el 6 de mayo de 2025}
}


@misc{Ahmad2025OCRNVidia,
  title         = {OpenCodeReasoning: Advancing Data Distillation for Competitive Coding},
  author        = {Wasi Uddin Ahmad and Sean Narenthiran and Somshubra Majumdar and Aleksander Ficek and Siddhartha Jain and Jocelyn Huang and Vahid Noroozi and Boris Ginsburg},
  year          = {2025},
  eprint        = {2504.01943},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2504.01943}
}

@misc{Moshkov2025AIMO2,
  title         = {AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset},
  author        = {Ivan Moshkov and Darragh Hanley and Ivan Sorokin and Shubham Toshniwal and Christof Henkel and Benedikt Schifferer and Wei Du and Igor Gitman},
  year          = {2025},
  eprint        = {2504.16891},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2504.16891}
}

@misc{Gou2024ToRA,
  title         = {ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving},
  author        = {Zhibin Gou and Zhihong Shao and Yeyun Gong and Yelong Shen and Yujiu Yang and Minlie Huang and Nan Duan and Weizhu Chen},
  year          = {2024},
  eprint        = {2309.17452},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2309.17452}
}

@misc{Unsloth2024Dataset1,
  author = {{Unsloth Team}},
  title  = {Datasets Guide - Unsloth Documentation},
  year   = {2024},
  url    = {https://docs.unsloth.ai/basics/datasets-guide#how-big-should-my-dataset-be},
  note   = {Accessed: 2025-04-25}
}

@misc{Unsloth2024WhatModel,
  author = {{Unsloth Team}},
  title  = {What Model Should I Use? - Unsloth Documentation},
  year   = {2024},
  url    = {https://docs.unsloth.ai/get-started/beginner-start-here/what-model-should-i-use},
  note   = {Accessed: 2025-04-25}
}

@misc{Wu2025AgenticReasoning,
  title         = {Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research},
  author        = {Junde Wu and Jiayuan Zhu and Yuyuan Liu},
  year          = {2025},
  eprint        = {2502.04644},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2502.04644}
}
@article{bm25Paper,
  author     = {Robertson, Stephen and Zaragoza, Hugo},
  title      = {The Probabilistic Relevance Framework: BM25 and Beyond},
  year       = {2009},
  issue_date = {April 2009},
  publisher  = {Now Publishers Inc.},
  address    = {Hanover, MA, USA},
  volume     = {3},
  number     = {4},
  issn       = {1554-0669},
  url        = {https://doi.org/10.1561/1500000019},
  doi        = {10.1561/1500000019},
  abstract   = {The Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970—1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the different ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.},
  journal    = {Found. Trends Inf. Retr.},
  month      = apr,
  pages      = {333–389},
  numpages   = {57}
}

@article{bertPaper,
  author     = {Jacob Devlin and
                Ming{-}Wei Chang and
                Kenton Lee and
                Kristina Toutanova},
  title      = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                Understanding},
  journal    = {CoRR},
  volume     = {abs/1810.04805},
  year       = {2018},
  url        = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint     = {1810.04805},
  timestamp  = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{gpt3Paper,
  author     = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert{-}Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  title      = {Language Models are Few-Shot Learners},
  journal    = {CoRR},
  volume     = {abs/2005.14165},
  year       = {2020},
  url        = {https://arxiv.org/abs/2005.14165},
  eprinttype = {arXiv},
  eprint     = {2005.14165},
  timestamp  = {Thu, 25 May 2023 10:38:31 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bleuPaper,
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  title     = {BLEU: a method for automatic evaluation of machine translation},
  year      = {2002},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  url       = {https://doi.org/10.3115/1073083.1073135},
  doi       = {10.3115/1073083.1073135},
  abstract  = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
  booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
  pages     = {311–318},
  numpages  = {8},
  location  = {Philadelphia, Pennsylvania},
  series    = {ACL '02}
}

@misc{rougePaper,
  title         = {ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks},
  author        = {Kavita Ganesan},
  year          = {2018},
  eprint        = {1803.01937},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/1803.01937}
}

@misc{bertscorePaper,
  title         = {BERTScore: Evaluating Text Generation with BERT},
  author        = {Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
  year          = {2020},
  eprint        = {1904.09675},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1904.09675}
}

@inproceedings{meteorPaper,
  author    = {Lavie, Alon and Agarwal, Abhaya},
  title     = {Meteor: an automatic metric for MT evaluation with high levels of correlation with human judgments},
  year      = {2007},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  abstract  = {Meteor is an automatic metric for Machine Translation evaluation which has been demonstrated to have high levels of correlation with human judgments of translation quality, significantly outperforming the more commonly used Bleu metric. It is one of several automatic metrics used in this year's shared task within the ACL WMT-07 workshop. This paper recaps the technical details underlying the metric and describes recent improvements in the metric. The latest release includes improved metric parameters and extends the metric to support evaluation of MT output in Spanish, French and German, in addition to English.},
  booktitle = {Proceedings of the Second Workshop on Statistical Machine Translation},
  pages     = {228–231},
  numpages  = {4},
  location  = {Prague, Czech Republic},
  series    = {StatMT '07}
}

@misc{t5GooglePaper,
  title         = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author        = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  year          = {2023},
  eprint        = {1910.10683},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1910.10683}
}


@misc{robertaPaper,
  title         = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author        = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  year          = {2019},
  eprint        = {1907.11692},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1907.11692}
}

@misc{Hu2021LoRA,
  title         = {LoRA: Low-Rank Adaptation of Large Language Models},
  author        = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  year          = {2021},
  eprint        = {2106.09685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2106.09685}
}

@misc{Holtzman2020NucleusSampling,
  title         = {The Curious Case of Neural Text Degeneration},
  author        = {Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
  year          = {2020},
  eprint        = {1904.09751},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1904.09751}
}

@misc{Wei2022FinetunedLMZeroShot,
  title         = {Finetuned Language Models Are Zero-Shot Learners},
  author        = {Jason Wei and Maarten Bosma and Vincent Y. Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
  year          = {2022},
  eprint        = {2109.01652},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2109.01652}
}


@inproceedings{Mishra2022CrossTaskGeneralization,
  title     = {Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
  author    = {Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  editor    = {Muresan, Smaranda and Nakov, Preslav and Villavicencio, Aline},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-long.244/},
  doi       = {10.18653/v1/2022.acl-long.244},
  pages     = {3470--3487},
  abstract  = {Humans (e.g., crowdworkers) have a remarkable ability in solving different tasks, by simply reading textual instructions that define them and looking at a few examples. Despite the success of the conventional supervised learning on individual datasets, such models often struggle with generalization across tasks (e.g., a question-answering system cannot solve classification tasks). A long-standing challenge in AI is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, we introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs). The instructions are obtained from crowdsourcing instructions used to create existing NLP datasets and mapped to a unified schema. Using this meta-dataset, we measure cross-task generalization by training models on seen tasks and measuring generalization to the remaining unseen ones. We adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Our results indicate that models benefit from instructions when evaluated in terms of generalization to unseen tasks (19{\%} better for models utilizing instructions). These models, however, are far behind an estimated performance upperbound indicating significant room for more progress in this direction.}
}

@inproceedings{Ouyang2022TrainingLMsIT,
  author    = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {27730--27744},
  publisher = {Curran Associates, Inc.},
  title     = {Training language models to follow instructions with human feedback},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022}
}

@misc{Pareja2024RecipesSFT,
  title         = {Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs},
  author        = {Aldo Pareja and Nikhil Shivakumar Nayak and Hao Wang and Krishnateja Killamsetty and Shivchander Sudalairaj and Wenlong Zhao and Seungwook Han and Abhishek Bhandwaldar and Guangxuan Xu and Kai Xu and Ligong Han and Luke Inglis and Akash Srivastava},
  year          = {2024},
  eprint        = {2412.13337},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2412.13337}
}


@misc{Zhang2024InstructionTuningLLM,
  title         = {Instruction Tuning for Large Language Models: A Survey},
  author        = {Shengyu Zhang and Linfeng Dong and Xiaoya Li and Sen Zhang and Xiaofei Sun and Shuhe Wang and Jiwei Li and Runyi Hu and Tianwei Zhang and Fei Wu and Guoyin Wang},
  year          = {2024},
  eprint        = {2308.10792},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2308.10792}
}


@misc{Wang2023AligningLargeLanguageModels,
  title         = {Aligning Large Language Models with Human: A Survey},
  author        = {Yufei Wang and Wanjun Zhong and Liangyou Li and Fei Mi and Xingshan Zeng and Wenyong Huang and Lifeng Shang and Xin Jiang and Qun Liu},
  year          = {2023},
  eprint        = {2307.12966},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2307.12966}
}


@misc{Ren2020CodeBLEU,
  title         = {CodeBLEU: a Method for Automatic Evaluation of Code Synthesis},
  author        = {Shuo Ren and Daya Guo and Shuai Lu and Long Zhou and Shujie Liu and Duyu Tang and Neel Sundaresan and Ming Zhou and Ambrosio Blanco and Shuai Ma},
  year          = {2020},
  eprint        = {2009.10297},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2009.10297}
}


@misc{Levi2024SimpleModelInferenceScalingLaws,
  title         = {A Simple Model of Inference Scaling Laws},
  author        = {Noam Levi},
  year          = {2024},
  eprint        = {2410.16377},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML},
  url           = {https://arxiv.org/abs/2410.16377}
}


@article{Vargas2021OSM,
  author   = {Vargas-Munoz, John E. and Srivastava, Shivangi and Tuia, Devis and Falcão, Alexandre X.},
  journal  = {IEEE Geoscience and Remote Sensing Magazine},
  title    = {OpenStreetMap: Challenges and Opportunities in Machine Learning and Remote Sensing},
  year     = {2021},
  volume   = {9},
  number   = {1},
  pages    = {184-199},
  keywords = {Machine learning;Navigation;Geographic information systems;Feature extraction;Urban areas;Remote sensing},
  doi      = {10.1109/MGRS.2020.2994107}
}
@misc{GeoJSON2025China,
  author       = {Eric Shi},
  title        = {geojson-map-china: GeoJSON data of China's administrative divisions},
  year         = {2025},
  url          = {https://github.com/longwosion/geojson-map-china},
  note         = {Accessed: 2025-06-14},
  howpublished = {\url{https://github.com/longwosion/geojson-map-china}},
  publisher    = {GitHub}
}


@misc{Li2024MuggleMath,
  title         = {MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning},
  author        = {Chengpeng Li and Zheng Yuan and Hongyi Yuan and Guanting Dong and Keming Lu and Jiancan Wu and Chuanqi Tan and Xiang Wang and Chang Zhou},
  year          = {2024},
  eprint        = {2310.05506},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.05506}
}

@misc{Dettmers2023QLora,
  title         = {QLoRA: Efficient Finetuning of Quantized LLMs},
  author        = {Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
  year          = {2023},
  eprint        = {2305.14314},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2305.14314}
}

@misc{Li2023BirdSQL,
  title         = {Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs},
  author        = {Jinyang Li and Binyuan Hui and Ge Qu and Jiaxi Yang and Binhua Li and Bowen Li and Bailin Wang and Bowen Qin and Rongyu Cao and Ruiying Geng and Nan Huo and Xuanhe Zhou and Chenhao Ma and Guoliang Li and Kevin C. C. Chang and Fei Huang and Reynold Cheng and Yongbin Li},
  year          = {2023},
  eprint        = {2305.03111},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.03111}
}


@misc{Dominguez2024BlarSQL,
  title         = {Blar-SQL: Faster, Stronger, Smaller NL2SQL},
  author        = {José Manuel Domínguez and Benjamín Errázuriz and Patricio Daher},
  year          = {2024},
  eprint        = {2401.02997},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2401.02997}
}


@misc{Lai2022DS1000,
  title         = {DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation},
  author        = {Yuhang Lai and Chengxi Li and Yiming Wang and Tianyi Zhang and Ruiqi Zhong and Luke Zettlemoyer and Scott Wen-tau Yih and Daniel Fried and Sida Wang and Tao Yu},
  year          = {2022},
  eprint        = {2211.11501},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2211.11501}
}


@misc{Seed2025SeedCoder,
  title         = {Seed-Coder: Let the Code Model Curate Data for Itself},
  author        = {ByteDance Seed and Yuyu Zhang and Jing Su and Yifan Sun and Chenguang Xi and Xia Xiao and Shen Zheng and Anxiang Zhang and Kaibo Liu and Daoguang Zan and Tao Sun and Jinhua Zhu and Shulin Xin and Dong Huang and Yetao Bai and Lixin Dong and Chao Li and Jianchong Chen and Hanzhi Zhou and Yifan Huang and Guanghan Ning and Xierui Song and Jiaze Chen and Siyao Liu and Kai Shen and Liang Xiang and Yonghui Wu},
  year          = {2025},
  eprint        = {2506.03524},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2506.03524}
}


@misc{Li2025LLMJudge,
  title         = {From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge},
  author        = {Dawei Li and Bohan Jiang and Liangjie Huang and Alimohammad Beigi and Chengshuai Zhao and Zhen Tan and Amrita Bhattacharjee and Yuxuan Jiang and Canyu Chen and Tianhao Wu and Kai Shu and Lu Cheng and Huan Liu},
  year          = {2025},
  eprint        = {2411.16594},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2411.16594}
}


@misc{Zhang2025DataSciBench,
  title         = {DataSciBench: An LLM Agent Benchmark for Data Science},
  author        = {Dan Zhang and Sining Zhoubian and Min Cai and Fengzu Li and Lekang Yang and Wei Wang and Tianjiao Dong and Ziniu Hu and Jie Tang and Yisong Yue},
  year          = {2025},
  eprint        = {2502.13897},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2502.13897}
}

@misc{Yao2025ArcticText2SQLR1,
  title         = {Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL},
  author        = {Zhewei Yao and Guoheng Sun and Lukasz Borchmann and Zheyu Shen and Minghang Deng and Bohan Zhai and Hao Zhang and Ang Li and Yuxiong He},
  year          = {2025},
  eprint        = {2505.20315},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2505.20315}
}


@misc{Yu2019Spider,
  title         = {Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task},
  author        = {Tao Yu and Rui Zhang and Kai Yang and Michihiro Yasunaga and Dongxu Wang and Zifan Li and James Ma and Irene Li and Qingning Yao and Shanelle Roman and Zilin Zhang and Dragomir Radev},
  year          = {2019},
  eprint        = {1809.08887},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1809.08887}
}

@misc{liu2019robertarobustlyoptimizedbert,
  title         = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author        = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  year          = {2019},
  eprint        = {1907.11692},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1907.11692}
}


@misc{brainacgan,
  author    = {Hossain, Md. Radowan and Shakiruzzaman and Ferdous, Gazi Jannatul and Hossain, Md. Azad},
  booktitle = {2024 International Conference on Innovations in Science, Engineering and Technology (ICISET)},
  title     = {BrainACGAN: Auxiliary Classifier Generative Adversarial Network for Brain Tumor Images},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {1-6},
  keywords  = {Deep learning;Accuracy;Machine learning algorithms;Image synthesis;Magnetic resonance imaging;Brain tumors;Medical services;Generative adversarial networks;Brain modeling;Medical diagnostic imaging;Generative adversarial network;Auxiliary classifier;Brain tumor;Deep learning;Image classification},
  doi       = {10.1109/ICISET62123.2024.10939632}
}

@misc{zhou2024automixqselfadjustingquantizationhigh,
  title         = {AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning},
  author        = {Changhai Zhou and Shiyang Zhang and Yuhua Zhou and Zekai Liu and Shichao Weng},
  year          = {2024},
  eprint        = {2411.13814},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2411.13814}
}

@misc{clarke1995situational,
  title        = {Situational crime prevention},
  author       = {Clarke, Ronald V.},
  journal      = {Crime and justice},
  volume       = {19},
  pages        = {91--150},
  year         = {1995},
  publisher    = {University of Chicago Press},
  doi          = {10.1086/449230},
  howpublished = {\url{https://doi.org/10.1086/449230}}
}
  title         = {AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning},
  author        = {Changhai Zhou and Shiyang Zhang and Yuhua Zhou and Zekai Liu and Shichao Weng},
  year          = {2024},
  eprint        = {2411.13814},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2411.13814}
}

@misc{Shi2024DecodingMethods,
  title         = {A Thorough Examination of Decoding Methods in the Era of LLMs},
  author        = {Chufan Shi and Haoran Yang and Deng Cai and Zhisong Zhang and Yifan Wang and Yujiu Yang and Wai Lam},
  year          = {2024},
  eprint        = {2402.06925},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.06925}
}


@misc{Minaee2025LLMSurvey,
  title         = {Large Language Models: A Survey},
  author        = {Shervin Minaee and Tomas Mikolov and Narjes Nikzad and Meysam Chenaghlu and Richard Socher and Xavier Amatriain and Jianfeng Gao},
  year          = {2025},
  eprint        = {2402.06196},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.06196}
}

@misc{Lin2025EfficientInferenceLLM,
  title         = {Efficient Inference for Large Language Model-based Generative Recommendation},
  author        = {Xinyu Lin and Chaoqun Yang and Wenjie Wang and Yongqi Li and Cunxiao Du and Fuli Feng and See-Kiong Ng and Tat-Seng Chua},
  year          = {2025},
  eprint        = {2410.05165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2410.05165}
}


@misc{Qin2025DynamicWidthSpeculativeBeamDecoding,
  title         = {Dynamic-Width Speculative Beam Decoding for Efficient LLM Inference},
  author        = {Zongyue Qin and Zifan He and Neha Prakriya and Jason Cong and Yizhou Sun},
  year          = {2025},
  eprint        = {2409.16560},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2409.16560}
}


@article{Choe2024EnhancingDataLiteracyLLMs,
  author   = {Choe, Kiroong and Lee, Chaerin and Lee, Soohyun and Song, Jiwon and Cho, Aeri and Kim, Nam Wook and Seo, Jinwook},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  title    = {Enhancing Data Literacy On-demand: LLMs as Guides for Novices in Chart Interpretation},
  year     = {2024},
  volume   = {},
  number   = {},
  pages    = {1-17},
  keywords = {Data visualization;Visualization;Task analysis;Education;Artificial intelligence;Annotations;Visual communication;Visualization literacy;large language model;visual communication},
  doi      = {10.1109/TVCG.2024.3413195}
}


@misc{Zeng2024AdvancingMLLMChartQA,
  title         = {Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning},
  author        = {Xingchen Zeng and Haichuan Lin and Yilin Ye and Wei Zeng},
  year          = {2024},
  eprint        = {2407.20174},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2407.20174}
}

@misc{Sah2024GeneratingAnalyticsDataVizLLMs,
  title         = {Generating Analytic Specifications for Data Visualization from Natural Language Queries using Large Language Models},
  author        = {Subham Sah and Rishab Mitra and Arpit Narechania and Alex Endert and John Stasko and Wenwen Dou},
  year          = {2024},
  eprint        = {2408.13391},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2408.13391}
}

@inproceedings{Li2024LinkQ,
  title     = {LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph Question-Answering},
  url       = {http://dx.doi.org/10.1109/VIS55277.2024.00031},
  doi       = {10.1109/vis55277.2024.00031},
  booktitle = {2024 IEEE Visualization and Visual Analytics (VIS)},
  publisher = {IEEE},
  author    = {Li, Harry and Appleby, Gabriel and Suh, Ashley},
  year      = {2024},
  month     = oct,
  pages     = {116–120}
}
