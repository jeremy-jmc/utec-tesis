@misc{Jiang2024UrbanLLM,
  title         = {UrbanLLM: Autonomous Urban Activity Planning and Management with Large Language Models},
  author        = {Yue Jiang and Qin Chao and Yile Chen and Xiucheng Li and Shuai Liu and Gao Cong},
  year          = {2024},
  eprint        = {2406.12360},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2406.12360}
}

@misc{Li2024UrbanGPT,
  title         = {UrbanGPT: Spatio-Temporal Large Language Models},
  author        = {Zhonghang Li and Lianghao Xia and Jiabin Tang and Yong Xu and Lei Shi and Long Xia and Dawei Yin and Chao Huang},
  year          = {2024},
  eprint        = {2403.00813},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2403.00813}
}

@misc{Deng2025VisualChronicles,
  title         = {Visual Chronicles: Using Multimodal LLMs to Analyze Massive Collections of Images},
  author        = {Boyang Deng and Songyou Peng and Kyle Genova and Gordon Wetzstein and Noah Snavely and Leonidas Guibas and Thomas Funkhouser},
  year          = {2025},
  eprint        = {2504.08727},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2504.08727}
}

@misc{Zhang2023GeoGPT,
  title         = {GeoGPT: Understanding and Processing Geospatial Tasks through An Autonomous GPT},
  author        = {Yifan Zhang and Cheng Wei and Shangyou Wu and Zhengting He and Wenhao Yu},
  year          = {2023},
  eprint        = {2307.07930},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2307.07930}
}

@misc{He2024GRetriever,
  title         = {G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering},
  author        = {Xiaoxin He and Yijun Tian and Yifei Sun and Nitesh V. Chawla and Thomas Laurent and Yann LeCun and Xavier Bresson and Bryan Hooi},
  year          = {2024},
  eprint        = {2402.07630},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.07630}
}

@misc{Dai2024QASTKG,
  title         = {Question Answering Over Spatio-Temporal Knowledge Graph},
  author        = {Xinbang Dai and Huiying Li and Guilin Qi},
  year          = {2024},
  eprint        = {2402.11542},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.11542}
}


@inproceedings{Saxena2021TemporalKGQA,
  title     = {Question Answering Over Temporal Knowledge Graphs},
  author    = {Saxena, Apoorv  and Chakrabarti, Soumen and Talukdar, Partha},
  editor    = {Zong, Chengqing  and Xia, Fei  and Li, Wenjie  and Navigli, Roberto},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.520/},
  doi       = {10.18653/v1/2021.acl-long.520},
  pages     = {6663--6676},
  abstract  = {Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broad coverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340x. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformer-based solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120{\%} in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well.}
}

@misc{Perozzi2024GraphToken,
  title         = {Let Your Graph Do the Talking: Encoding Structured Data for LLMs},
  author        = {Bryan Perozzi and Bahare Fatemi and Dustin Zelle and Anton Tsitsulin and Mehran Kazemi and Rami Al-Rfou and Jonathan Halcrow},
  year          = {2024},
  eprint        = {2402.05862},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.05862}
}


@misc{Fatemi2023GraphEncoding,
  title         = {Talk like a Graph: Encoding Graphs for Large Language Models},
  author        = {Bahare Fatemi and Jonathan Halcrow and Bryan Perozzi},
  year          = {2023},
  eprint        = {2310.04560},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2310.04560}
}

@article{Zhang2025CrimeDatasetChina,
  author   = {Yan Zhang and Mei-Po Kwan and Libo Fang},
  title    = {An LLM driven dataset on the spatiotemporal distributions of street and neighborhood crime in China},
  journal  = {Scientific Data},
  volume   = {12},
  number   = {1},
  pages    = {467},
  year     = {2025},
  month    = {mar},
  doi      = {10.1038/s41597-025-04757-8},
  url      = {https://doi.org/10.1038/s41597-025-04757-8},
  issn     = {2052-4463},
  abstract = {Crime is a significant social, economic, and legal issue. This research presents an open-access spatiotemporal repository of street and neighborhood crime data, comprising approximately one million records of crimes in China, with specific geographic coordinates (latitude and longitude) and timestamps for each incident. The dataset is based on publicly available law court judgment documents. Artificial intelligence (AI) technologies are employed to extract crime events at the neighborhood or even building level from vast amounts of unstructured judicial text. This dataset enables more precise spatial analysis of crime incidents, offering valuable insights across interdisciplinary fields such as economics, sociology, and geography. It contributes significantly to the achievement of the United Nations Sustainable Development Goals (SDGs), particularly in fostering sustainable cities and communities, and plays a crucial role in advancing efforts to reduce all forms of violence and related mortality rates.}
}

@misc{NYCDataset,
  title        = {NYPD Complaint Data Historic},
  author       = {New York City Police Department},
  year         = {2025},
  howpublished = {\url{https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qb7u-rbmr}}
}

@misc{ChicagoDataset,
  title        = {Crimes - 2001 to Present},
  author       = {Chicago Police Department},
  year         = {2024},
  howpublished = {\url{https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2}}
}

@article{Garcia2022CriPAV,
  author   = {García-Zanabria, Germain and Raimundo, Marcos M. and Poco, Jorge and Nery, Marcelo Batista and Silva, Cláudio T. and Adorno, Sergio and Nonato, Luis Gustavo},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  title    = {CriPAV: Street-Level Crime Patterns Analysis and Visualization},
  year     = {2022},
  volume   = {28},
  number   = {12},
  pages    = {4000-4015},
  abstract = {Extracting and analyzing crime patterns in big cities is a challenging spatiotemporal problem. The hardness of the problem is linked to two main factors, the sparse nature of the crime activity and its spread in large spatial areas. Sparseness hampers most time series (crime time series) comparison methods from working properly, while the handling of large urban areas tends to render the computational costs of such methods impractical. Visualizing different patterns hidden in crime time series data is another issue in this context, mainly due to the number of patterns that can show up in the time series analysis. In this article, we present a new methodology to deal with the issues above, enabling the analysis of spatiotemporal crime patterns in a street-level of detail. Our approach is made up of two main components designed to handle the spatial sparsity and spreading of crimes in large areas of the city. The first component relies on a stochastic mechanism from which one can visually analyze probable×intensive crime hotspots. Such analysis reveals important patterns that can not be observed in the typical intensity-based hotspot visualization. The second component builds upon a deep learning mechanism to embed crime time series in Cartesian space. From the embedding, one can identify spatial locations where the crime time series have similar behavior. The two components have been integrated into a web-based analytical tool called CriPAV (Crime Pattern Analysis and Visualization), which enables global as well as a street-level view of crime patterns. Developed in close collaboration with domain experts, CriPAV has been validated through a set of case studies with real crime data in São Paulo - Brazil. The provided experiments and case studies reveal the effectiveness of CriPAV in identifying patterns such as locations where crimes are not intense but highly probable to occur as well as locations that are far apart from each other but bear similar crime patterns.},
  keywords = {Data visualization;Time series analysis;Urban areas;Spatiotemporal phenomena;Stochastic processes;Deep learning;Visual analytics;Criminal law;Crime data;spatio-temporal data;visual analytics;crime hotspots;stochastic matrix},
  doi      = {10.1109/TVCG.2021.3111146},
  issn     = {1941-0506},
  month    = {Dec}
}

@article{Garcia2020MiranteAV,
  title   = {Mirante: A visualization tool for analyzing urban crimes},
  author  = {Germain Garcia Zanabria and Erick Gomez Nieto and Jaqueline Silveira and Jorge Poco and Marcelo Batista Nery and Sergio Adorno and Luis Gustavo Nonato},
  journal = {2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},
  year    = {2020},
  pages   = {148-155},
  url     = {https://api.semanticscholar.org/CorpusID:227221852}
}

@article{Garcia2021CrimAnalyzer,
  title     = {CrimAnalyzer: Understanding Crime Patterns in São Paulo},
  volume    = {27},
  issn      = {2160-9306},
  url       = {http://dx.doi.org/10.1109/TVCG.2019.2947515},
  doi       = {10.1109/tvcg.2019.2947515},
  number    = {4},
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Garcia, Germain and Silveira, Jaqueline and Poco, Jorge and Paiva, Afonso and Nery, Marcelo Batista and Silva, Claudio T. and Adorno, Sergio and Nonato, Luis Gustavo},
  year      = {2021},
  month     = apr,
  pages     = {2313-2328}
}

@misc{Liu2024NLDriven,
  title         = {Breathing New Life into Existing Visualizations: A Natural Language-Driven Manipulation Framework},
  author        = {Can Liu and Jiacheng Yu and Yuhan Guo and Jiayi Zhuang and Yuchu Luo and Xiaoru Yuan},
  year          = {2024},
  eprint        = {2404.06039},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2404.06039}
}

@article{Wu2024LLMVis,
  author     = {Wu, Yang and Wan, Yao and Zhang, Hongyu and Sui, Yulei and Wei, Wucai and Zhao, Wei and Xu, Guandong and Jin, Hai},
  title      = {Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study},
  year       = {2024},
  issue_date = {June 2024},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {2},
  number     = {3},
  url        = {https://doi.org/10.1145/3654992},
  doi        = {10.1145/3654992},
  abstract   = {The Natural Language to Visualization (NL2Vis) task aims to transform natural-language descriptions into visual representations for a grounded table, enabling users to gain insights from vast amounts of data. Recently, many deep learning-based approaches have been developed for NL2Vis. Despite the considerable efforts made by these approaches, challenges persist in visualizing data sourced from unseen databases or spanning multiple tables. Taking inspiration from the remarkable generation capabilities of Large Language Models (LLMs), this paper conducts an empirical study to evaluate their potential in generating visualizations, and explore the effectiveness of in-context learning prompts for enhancing this task. In particular, we first explore the ways of transforming structured tabular data into sequential text prompts, as to feed them into LLMs and analyze which table content contributes most to the NL2Vis. Our findings suggest that transforming structured tabular data into programs is effective, and it is essential to consider the table schema when formulating prompts. Furthermore, we evaluate two types of LLMs: finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5), against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench). The experimental results reveal that LLMs outperform baselines, with inference-only models consistently exhibiting performance improvements, at times even surpassing fine-tuned models when provided with certain few-shot demonstrations through in-context learning. Finally, we analyze when the LLMs fail in NL2Vis, and propose to iteratively update the results using strategies such as chain-of-thought, role-playing, and code-interpreter. The experimental results confirm the efficacy of iterative updates and hold great potential for future study.},
  journal    = {Proc. ACM Manag. Data},
  month      = may,
  articleno  = {115},
  numpages   = {28},
  keywords   = {code generation, data analysis, data visualization, exploratory study, large language models, natural language processing}
}

@article{Luo2022NL2Vis,
  author   = {Luo, Yuyu and Tang, Nan and Li, Guoliang and Tang, Jiawei and Chai, Chengliang and Qin, Xuedi},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  title    = {Natural Language to Visualization by Neural Machine Translation},
  year     = {2022},
  volume   = {28},
  number   = {1},
  pages    = {217-226},
  keywords = {Data visualization;Natural languages;Bars;Deep learning;Machine translation;Visualization;Transformers;Natural language interface;data visualization;neural machine translation;chart template},
  doi      = {10.1109/TVCG.2021.3114848}
}


@article{Narechania2021NL4DV,
  title     = {NL4DV: A Toolkit for Generating Analytic Specifications for Data Visualization from Natural Language Queries},
  volume    = {27},
  issn      = {2160-9306},
  url       = {http://dx.doi.org/10.1109/TVCG.2020.3030378},
  doi       = {10.1109/tvcg.2020.3030378},
  number    = {2},
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Narechania, Arpit and Srinivasan, Arjun and Stasko, John},
  year      = {2021},
  month     = feb,
  pages     = {369-379}
}

@inproceedings{Liu2021ADVISor,
  author    = {Liu, Can and Han, Yun and Jiang, Ruike and Yuan, Xiaoru},
  booktitle = {2021 IEEE 14th Pacific Visualization Symposium (PacificVis)},
  title     = {ADVISor: Automatic Visualization Answer for Natural-Language Question on Tabular Data},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {11-20},
  keywords  = {Annotations;Natural languages;Pipelines;Neural networks;Data visualization;Tools;Data mining;Question answering;natural language;visualization;annotation;tabular data;machine learning;deep learning},
  doi       = {10.1109/PacificVis52677.2021.00010}
}

@inproceedings{Setlur2016Eviza,
  author    = {Setlur, Vidya and Battersby, Sarah E. and Tory, Melanie and Gossweiler, Rich and Chang, Angel X.},
  title     = {Eviza: A Natural Language Interface for Visual Analysis},
  year      = {2016},
  isbn      = {9781450341899},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2984511.2984588},
  doi       = {10.1145/2984511.2984588},
  abstract  = {Natural language interfaces for visualizations have emerged as a promising new way of interacting with data and performing analytics. Many of these systems have fundamental limitations. Most return minimally interactive visualizations in response to queries and often require experts to perform modeling for a set of predicted user queries before the systems are effective. Eviza provides a natural language interface for an interactive query dialog with an existing visualization rather than starting from a blank sheet and asking closed-ended questions that return a single text answer or static visualization. The system employs a probabilistic grammar based approach with predefined rules that are dynamically updated based on the data from the visualization, as opposed to computationally intensive deep learning or knowledge based approaches.The result of an interaction is a change to the view (e.g., filtering, navigation, selection) providing graphical answers and ambiguity widgets to handle ambiguous queries and system defaults. There is also rich domain awareness of time, space, and quantitative reasoning built in, and linking into existing knowledge bases for additional semantics. Eviza also supports pragmatics and exploring multi-modal interactions to help enhance the expressiveness of how users can ask questions about their data during the flow of visual analysis.},
  booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
  pages     = {365-377},
  numpages  = {13},
  keywords  = {visualization, visual data analysis, probabilistic grammar, pragmatics, parser, natural language, ambiguity},
  location  = {Tokyo, Japan},
  series    = {UIST '16}
}

@article{Salah2022BigCDVis,
  title   = {Big Crime Data Analytics and Visualization},
  author  = {Mokhtar Mansour Salah and Ke-wen Xia},
  journal = {Proceedings of the 2022 6th International Conference on Compute and Data Analysis},
  year    = {2022},
  url     = {https://api.semanticscholar.org/CorpusID:248990234}
}

@inproceedings{Silva2017CrimeVisAI,
  title     = {CrimeVis: An Interactive Visualization System for Analyzing Crime Data in the State of Rio de Janeiro},
  author    = {Luiz Jos{\'e} Schirmer Silva and Sonia Fiol-Gonz{\'a}lez and Cassio F. P. Almeida and Simone Diniz Junqueira Barbosa and H{\'e}lio C{\^o}rtes Vieira Lopes},
  booktitle = {International Conference on Enterprise Information Systems},
  year      = {2017},
  url       = {https://api.semanticscholar.org/CorpusID:46819581}
}

@inproceedings{Almuhanna2021CrimeNYC,
  author    = {Almuhanna, Abrar A. and Alrehili, Marwa M. and Alsubhi, Samah H. and Syed, Liyakathunisa},
  booktitle = {2021 1st International Conference on Artificial Intelligence and Data Analytics (CAIDA)},
  title     = {Prediction of Crime in Neighbourhoods of New York City using Spatial Data Analysis},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {23-30},
  keywords  = {Support vector machines;Deep learning;Radio frequency;Data analysis;Law enforcement;Urban areas;Data visualization;Spatio-temporal patterns;Crime;Neighbourhoods Prediction;Data Visualization;SVM;Random Forest;XGboost},
  doi       = {10.1109/CAIDA51941.2021.9425120}
}

@article{Ersoz2025CrimePredictionXAISurvey,
  author   = {Ersöz, Filiz and Ersöz, Taner and Marcelloni, Francesco and Ruffini, Fabrizio},
  journal  = {IEEE Access},
  title    = {Artificial Intelligence in Crime Prediction: A Survey With a Focus on Explainability},
  year     = {2025},
  volume   = {13},
  number   = {},
  pages    = {59646-59674},
  keywords = {Artificial intelligence;Law enforcement;Predictive models;Accuracy;Explainable AI;Reviews;Prevention and mitigation;Ethics;Surveys;Market research;Crime prediction;artificial intelligence;explainability;interpretability;crime datasets;survey},
  doi      = {10.1109/ACCESS.2025.3553934}
}


@misc{Utsha2024DLCrimeAnalysis,
  title         = {Deep Learning Based Crime Prediction Models: Experiments and Analysis},
  author        = {Rittik Basak Utsha and Muhtasim Noor Alif and Yeasir Rayhan and Tanzima Hashem and Mohammad Eunus Ali},
  year          = {2024},
  eprint        = {2407.19324},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2407.19324}
}


@misc{Yu2025SpatialRAG,
  title         = {Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions},
  author        = {Dazhou Yu and Riyang Bao and Gengchen Mai and Liang Zhao},
  year          = {2025},
  eprint        = {2502.18470},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2502.18470}
}

@misc{Hu2024GRAG,
  title         = {GRAG: Graph Retrieval-Augmented Generation},
  author        = {Yuntong Hu and Zhihan Lei and Zheng Zhang and Bo Pan and Chen Ling and Liang Zhao},
  year          = {2024},
  eprint        = {2405.16506},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2405.16506}
}


@misc{Edge2025GraphRAG,
  title         = {From Local to Global: A Graph RAG Approach to Query-Focused Summarization},
  author        = {Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Dasha Metropolitansky and Robert Osazuwa Ness and Jonathan Larson},
  year          = {2025},
  eprint        = {2404.16130},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2404.16130}
}
@misc{Guo2024LightRAG,
  title         = {LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author        = {Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year          = {2024},
  eprint        = {2410.05779},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2410.05779}
}

@misc{Xiao2024TimeRAG,
  title  = {Time{RAG}: It's Time for Retrieval-Augmented Generation in Time-Series Forecasting},
  author = {Mengxi Xiao and Zihao Jiang and Zhengyu Chen and Dong Li and Shuai Chen and Sophia Ananiadou and Jimin Huang and Min Peng and Qianqian Xie},
  year   = {2024},
  url    = {https://openreview.net/forum?id=GvzL4LuycW}
}

@misc{Yang2024TimeRAG,
  title         = {TimeRAG: BOOSTING LLM Time Series Forecasting via Retrieval-Augmented Generation},
  author        = {Silin Yang and Dong Wang and Haoqi Zheng and Ruochun Jin},
  year          = {2024},
  eprint        = {2412.16643},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2412.16643}
}

@inproceedings{Xu2024RAGKG,
  series     = {SIGIR 2024},
  title      = {Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering},
  url        = {http://dx.doi.org/10.1145/3626772.3661370},
  doi        = {10.1145/3626772.3661370},
  booktitle  = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  publisher  = {ACM},
  author     = {Xu, Zhentao and Cruz, Mark Jerome and Guevara, Matthew and Wang, Tie and Deshpande, Manasi and Wang, Xiaofeng and Li, Zheng},
  year       = {2024},
  month      = jul,
  pages      = {2905-2909},
  collection = {SIGIR 2024}
}

@inproceedings{Chen2025KGRAGSurvey,
  title     = {Retrieval-Augmented Generation with Knowledge Graphs: A Survey},
  author    = {Chen, Ruixi},
  year      = {2025},
  booktitle = {Computer Science Undergradaute Conference 2025@ XJTU}
}


@article{Pappula2023LLMsFC,
  title   = {LLMs for Conversational AI: Enhancing Chatbots and Virtual Assistants},
  author  = {Sharmila Reddy Pappula and Sathwik Rao Allam},
  journal = {International Journal of Research Publication and Reviews},
  year    = {2023},
  url     = {https://api.semanticscholar.org/CorpusID:266461220}
}



@article{Machado2012CrimeRJ,
  title   = {Medo Social e Turismo no Rio de Janeiro},
  author  = {Marcello de Barros Tom{\'e} Machado},
  journal = {Tourism \& Management Studies},
  year    = {2012},
  pages   = {48-54},
  url     = {https://api.semanticscholar.org/CorpusID:155721043}
}


@article{SopikoTevdoradze2024CrimeTourism,
  title   = {The Effect of Criminal Activity on Tourism},
  author  = {Sopiko Tevdoradze Sopiko Tevdoradze and Zurab Mushkudiani Zurab Mushkudiani and Nugzar Tevdoradze Nugzar Tevdoradze},
  journal = {The New Economist},
  year    = {2024},
  url     = {https://api.semanticscholar.org/CorpusID:273525446}
}

@misc{Contractor2020QATourism,
  title         = {Large Scale Question Answering using Tourism Data},
  author        = {Danish Contractor and Krunal Shah and Aditi Partap and Mausam and Parag Singla},
  year          = {2020},
  eprint        = {1909.03527},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1909.03527}
}

@misc{Wei2024TourLLM,
  title         = {TourLLM: Enhancing LLMs with Tourism Knowledge},
  author        = {Qikai Wei and Mingzhi Yang and Jinqiang Wang and Wenwei Mao and Jiabo Xu and Huansheng Ning},
  year          = {2024},
  eprint        = {2407.12791},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2407.12791}
}

@article{Zengli2020CrimePatterns,
  author         = {Wang, Zengli and Zhang, Hong},
  title          = {Construction, Detection, and Interpretation of Crime Patterns over Space and Time},
  journal        = {ISPRS International Journal of Geo-Information},
  volume         = {9},
  year           = {2020},
  number         = {6},
  article_number = {339},
  url            = {https://www.mdpi.com/2220-9964/9/6/339},
  issn           = {2220-9964},
  abstract       = {Empirical studies have focused on investigating the interactive relationships between crime pairs. However, many other types of crime patterns have not been extensively investigated. In this paper, we introduce three basic crime patterns in four combinations. Based on graph theory, the subgraphs for each pattern were constructed and analyzed using criminology theories. A Monte Carlo simulation was conducted to examine the significance of these patterns. Crime patterns were statistically significant and generated different levels of crime risk. Compared to the classical patterns, combined patterns create much higher risk levels. Among these patterns, “co-occurrence, repeat, and shift” generated the highest level of crime risk, while “repeat” generated much lower levels of crime risk. “Co-occurrence and shift” and “repeat and shift” showed undulated risk levels, while others showed a continuous decrease. These results outline the importance of proposed crime patterns and call for differentiated crime prevention strategies. This method can be extended to other research areas that use point events as research objects.},
  doi            = {10.3390/ijgi9060339}
}


@misc{vaswani2023attentionneed,
  title         = {Attention Is All You Need},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year          = {2023},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1706.03762}
}

@misc{RAG2021,
  title         = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author        = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  year          = {2021},
  eprint        = {2005.11401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.11401}
}

@misc{modularRAG2024,
  title         = {Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks},
  author        = {Yunfan Gao and Yun Xiong and Meng Wang and Haofen Wang},
  year          = {2024},
  eprint        = {2407.21059},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2407.21059}
}

@misc{chainofthought2023,
  title         = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author        = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year          = {2023},
  eprint        = {2201.11903},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2201.11903}
}

@misc{fewshot2020,
  title         = {Language Models are Few-Shot Learners},
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year          = {2020},
  eprint        = {2005.14165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.14165}
}
@article{Yang2024HumanAIInteraction,
  title   = {Human-AI Interaction in the Age of LLMs},
  author  = {Diyi Yang and Sherry Tongshuang Wu and Marti A. Hearst},
  journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 5: Tutorial Abstracts)},
  year    = {2024},
  url     = {https://api.semanticscholar.org/CorpusID:270514463}
}


@inproceedings{Waqar2025CrimePredictionGNN,
  author    = {Hassan, Waqar and Cabral, Marvin Mendes and Ramos, Thiago Rodrigo and Filho, Antonio Castelo and Nonato, Luis Gustavo},
  editor    = {Paes, Aline and Verri, Filipe A. N.},
  title     = {Modeling and Predicting Crimes in the City of Sao Paulo Using Graph Neural Networks},
  booktitle = {Intelligent Systems},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {372--386},
  abstract  = {Crime prediction is a critical research area for enhancing public safety and optimizing law enforcement resource allocation, and machine learning techniques have had a significant impact in this field. Traditional machine learning models have long struggled to capture complex crime patterns, primarily due to the intricate interdependence of spatial and temporal data. However, recent advancements in machine learning, particularly with Graph Neural Networks (GNNs), offer a new perspective. GNNs have demonstrated remarkable success in various applications and they can also play a significant role in crime analysis and prediction. Therefore, in this work, we explore such a potential by examining two distinct spatiotemporal GNN architectures, namely Dynamic Self-Attention Network (DySAT) and Evolving Graph Convolutional Network (EvolveGCN), assessing and comparing their effectiveness for crime prediction. Moreover, we propose a data modeling framework that integrates crime, street map graphs, and urban data, which is fundamental to properly train the GNN models. As far as we know, there is no consolidated methodology to integrate those three modalities of data, being a relevant contribution of this work. Our findings underscore the effectiveness of GNNs in crime prediction tasks, offering valuable insights for researchers and practitioners in the field of crime prevention and public safety enhancement.},
  isbn      = {978-3-031-79035-5}
}


@misc{2025GoogleGeospatialReasoning,
  author       = {Schottlander, David and Shekel, Tomer},
  title        = {Geospatial Reasoning: Unlocking insights with generative AI and multiple foundation models},
  howpublished = {Google Research Blog},
  month        = apr,
  year         = {2025},
  note         = {Available at: \url{https://research.google/blog/geospatial-reasoning-unlocking-insights-with-generative-ai-and-multiple-foundation-models/} (Accessed: 2025-04-18)}
}


@misc{Qwen2025Qwen2.5,
  title         = {Qwen2.5 Technical Report},
  author        = {Qwen and others},
  year          = {2025},
  eprint        = {2412.15115},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2412.15115}
}


@misc{Grattafiori2024Llama3,
  title         = {The Llama 3 Herd of Models},
  author        = {Aaron Grattafiori et al.},
  year          = {2024},
  eprint        = {2407.21783},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2407.21783}
}


@misc{Nvidia2024KaggleMath,
  author = {{NVIDIA Blog Team}},
  title  = {How AI Reasoning Is Being Tested with International Math Olympiad Problems},
  year   = {2024},
  url    = {https://blogs.nvidia.com/blog/reasoning-ai-math-olympiad/},
  note   = {Accessed: 2025-04-20}
}

@misc{Fleureau2024NuminaMath,
  author       = {Fleureau, Yann and Li, Jia and Beeching, Edward and 
                  Tunstall, Lewis and Lipkin, Ben and Soletskyi, Roman and 
                  Costa Huang, Shengyi and Rasul, Kashif},
  title        = {How NuminaMath Won the 1st AIMO Progress Prize},
  year         = {2024},
  month        = {jul},
  day          = {11},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/blog/winning-aimo-progress-prize}},
  note         = {Blog post, consultado el 6 de mayo de 2025}
}

@techreport{Li2024NuminaMath,
  title       = {NuminaMath: The largest public dataset in AI4Maths with 860k pairs of competition math problems and solutions},
  author      = {Jia Li and Edward Beeching and Lewis Tunstall and Ben Lipkin and Roman Soletskyi and Shengyi Huang and Kashif Rasul and Longhui Yu and Albert Q. Jiang and Ziju Shen and Zihan Qin and Bin Dong and Li Zhou and Yann Fleureau and Guillaume Lample and Stanislas Polu},
  institution = {Numina, Hugging Face, MIT, Mistral AI, Peking University, Answer AI},
  year        = {2024},
  month       = {July},
  url         = {https://github.com/project-numina/aimo-progress-prize/blob/main/report/numina_dataset.pdf},
  note        = {Winner of the 1st AIMO Progress Prize}
}

@misc{Wang2023SelfConsistency,
  title         = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author        = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
  year          = {2023},
  eprint        = {2203.11171},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2203.11171}
}

@misc{Yin2024MuMathCode,
  title         = {MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning},
  author        = {Shuo Yin and Weihao You and Zhilong Ji and Guoqiang Zhong and Jinfeng Bai},
  year          = {2024},
  eprint        = {2405.07551},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2405.07551}
}


@misc{Jain2024MetaFineTuning,
  author       = {Jain, Aditya and Maleki, Amir and Saade, Nathalie},
  title        = {How to fine-tune: Focus on effective datasets},
  year         = {2024},
  month        = {aug},
  day          = {7},
  publisher    = {Meta AI},
  howpublished = {\url{https://ai.meta.com/blog/how-to-fine-tune-llms-peft-dataset-curation/}},
  note         = {Blog post, consultado el 6 de mayo de 2025}
}


@misc{Ahmad2025OCRNVidia,
      title={OpenCodeReasoning: Advancing Data Distillation for Competitive Coding}, 
      author={Wasi Uddin Ahmad and Sean Narenthiran and Somshubra Majumdar and Aleksander Ficek and Siddhartha Jain and Jocelyn Huang and Vahid Noroozi and Boris Ginsburg},
      year={2025},
      eprint={2504.01943},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.01943}, 
}

@misc{Moshkov2025AIMO2,
  title         = {AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset},
  author        = {Ivan Moshkov and Darragh Hanley and Ivan Sorokin and Shubham Toshniwal and Christof Henkel and Benedikt Schifferer and Wei Du and Igor Gitman},
  year          = {2025},
  eprint        = {2504.16891},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2504.16891}
}

@misc{Unsloth2024Dataset1,
  author = {{Unsloth Team}},
  title  = {Datasets Guide - Unsloth Documentation},
  year   = {2024},
  url    = {https://docs.unsloth.ai/basics/datasets-guide#how-big-should-my-dataset-be},
  note   = {Accessed: 2025-04-25}
}

@misc{Unsloth2024WhatModel,
  author = {{Unsloth Team}},
  title  = {What Model Should I Use? - Unsloth Documentation},
  year   = {2024},
  url    = {https://docs.unsloth.ai/get-started/beginner-start-here/what-model-should-i-use},
  note   = {Accessed: 2025-04-25}
}

@misc{Wu2025AgenticReasoning,
  title         = {Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research},
  author        = {Junde Wu and Jiayuan Zhu and Yuyuan Liu},
  year          = {2025},
  eprint        = {2502.04644},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2502.04644}
}
@article{bm25Paper,
  author     = {Robertson, Stephen and Zaragoza, Hugo},
  title      = {The Probabilistic Relevance Framework: BM25 and Beyond},
  year       = {2009},
  issue_date = {April 2009},
  publisher  = {Now Publishers Inc.},
  address    = {Hanover, MA, USA},
  volume     = {3},
  number     = {4},
  issn       = {1554-0669},
  url        = {https://doi.org/10.1561/1500000019},
  doi        = {10.1561/1500000019},
  abstract   = {The Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970—1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the different ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.},
  journal    = {Found. Trends Inf. Retr.},
  month      = apr,
  pages      = {333–389},
  numpages   = {57}
}

@article{bertPaper,
  author     = {Jacob Devlin and
                Ming{-}Wei Chang and
                Kenton Lee and
                Kristina Toutanova},
  title      = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                Understanding},
  journal    = {CoRR},
  volume     = {abs/1810.04805},
  year       = {2018},
  url        = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint     = {1810.04805},
  timestamp  = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{gpt3Paper,
  author     = {Tom B. Brown and
                Benjamin Mann and
                Nick Ryder and
                Melanie Subbiah and
                Jared Kaplan and
                Prafulla Dhariwal and
                Arvind Neelakantan and
                Pranav Shyam and
                Girish Sastry and
                Amanda Askell and
                Sandhini Agarwal and
                Ariel Herbert{-}Voss and
                Gretchen Krueger and
                Tom Henighan and
                Rewon Child and
                Aditya Ramesh and
                Daniel M. Ziegler and
                Jeffrey Wu and
                Clemens Winter and
                Christopher Hesse and
                Mark Chen and
                Eric Sigler and
                Mateusz Litwin and
                Scott Gray and
                Benjamin Chess and
                Jack Clark and
                Christopher Berner and
                Sam McCandlish and
                Alec Radford and
                Ilya Sutskever and
                Dario Amodei},
  title      = {Language Models are Few-Shot Learners},
  journal    = {CoRR},
  volume     = {abs/2005.14165},
  year       = {2020},
  url        = {https://arxiv.org/abs/2005.14165},
  eprinttype = {arXiv},
  eprint     = {2005.14165},
  timestamp  = {Thu, 25 May 2023 10:38:31 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bleuPaper,
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  title     = {BLEU: a method for automatic evaluation of machine translation},
  year      = {2002},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  url       = {https://doi.org/10.3115/1073083.1073135},
  doi       = {10.3115/1073083.1073135},
  abstract  = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
  booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
  pages     = {311–318},
  numpages  = {8},
  location  = {Philadelphia, Pennsylvania},
  series    = {ACL '02}
}

@misc{rougePaper,
  title         = {ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks},
  author        = {Kavita Ganesan},
  year          = {2018},
  eprint        = {1803.01937},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/1803.01937}
}

@misc{bertscorePaper,
  title         = {BERTScore: Evaluating Text Generation with BERT},
  author        = {Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
  year          = {2020},
  eprint        = {1904.09675},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1904.09675}
}

@inproceedings{meteorPaper,
  author    = {Lavie, Alon and Agarwal, Abhaya},
  title     = {Meteor: an automatic metric for MT evaluation with high levels of correlation with human judgments},
  year      = {2007},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  abstract  = {Meteor is an automatic metric for Machine Translation evaluation which has been demonstrated to have high levels of correlation with human judgments of translation quality, significantly outperforming the more commonly used Bleu metric. It is one of several automatic metrics used in this year's shared task within the ACL WMT-07 workshop. This paper recaps the technical details underlying the metric and describes recent improvements in the metric. The latest release includes improved metric parameters and extends the metric to support evaluation of MT output in Spanish, French and German, in addition to English.},
  booktitle = {Proceedings of the Second Workshop on Statistical Machine Translation},
  pages     = {228–231},
  numpages  = {4},
  location  = {Prague, Czech Republic},
  series    = {StatMT '07}
}

@misc{t5GooglePaper,
  title         = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author        = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  year          = {2023},
  eprint        = {1910.10683},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1910.10683}
}


@misc{robertaPaper,
  title         = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author        = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  year          = {2019},
  eprint        = {1907.11692},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1907.11692}
}

