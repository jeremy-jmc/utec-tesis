\customchapter{CONCLUSIONS AND FUTURE WORK} 

\section{Conclusions}


% Este trabajo es el primero buscar sentar la base para el uso de modelos de lenguaje grande (LLMs) en la evaluacion de data criminal. El enfoque de usar una LLM finetuneada demuestra que se requiere un dataset mas robusto especializado para que el modelo pueda analizar correctamente los datos baseado en generacioon de codigo como se hace para el ambio de resolucion de problemas de matematica.
% Usando un enfoque de synthetic data generation usando un modelo mas grande, demostramos a traves de un caso de estudio que las LLMs tienen el potencial de ser una herramienta valiosa para la evaluacion de datos criminales, permitiendo a los usuarios realizar consultas complejas y obtener respuestas trazables.
% This study ... By using ... These findings ...

This study represents the first comprehensive approach to establish a foundation for using large language models (LLMs) in criminal data evaluation through code-backed answers. By using a fine-tuned LLaMA3-8B model trained on the ChinaCrimeQACode dataset containing 5,000 question-code pairs, we highlight the necessity of a more robust, domain-specific dataset for the model to accurately analyze crime data. These findings reveal that while specialized datasets are essential for effective crime data analysis, the approach of code generation, similar to mathematical problem-solving domains, enables traceable and interpretable responses that can facilitate informed decision-making for both citizens and law enforcement authorities.

% The approach of synthetic data generation using a larger model demonstrates that LLMs have the potential to be valuable tools for crime data evaluation, enabling users to perform complex queries and obtain traceable answers. 


\section{Limitations and Future Work}

During our experiments with the finetuned model, we identified several significant limitations in both the model and the dataset. Addressing these limitations is essential for enhancing the model's performance and usability. For example, when queries include coordinates (latitude and longitude) in a format different from the dataset's standard ('[lat, long]'), the model consistently fails to provide accurate or approximate answers. Additionally, the model struggles with queries that contain misspellings or alternative names for specific information, such as locations or types of crimes, that differ from those in the dataset. For instance, when asked "How many crimes occurred in Guangdong?" instead of "How many crimes occurred in Guangdong Province?", the model is unable to produce a correct response.

To address these challenges, future work will focus on enhancing both the dataset and the model. For the dataset, we propose expanding its geographical coverage to include regions such as Brazil, New York, and potentially Lima, thereby improving the model's generalizability across diverse contexts. Additionally, incorporating a "LLM-as-a-judge" mechanism during the dataset construction phase, by verifying whether the model's outputs for paraphrased or altered questions align with the original, could enhance label reliability and consistency. Scaling the dataset to at least 10,000 records is another priority, as this would provide a richer training environment and enable the model to generalize more effectively across a broader range of queries.

On the modeling side, we aim to enhance the alignment between the model’s textual outputs and the visual feedback provided to users. This can be achieved by integrating a visualization tool capable of displaying maps and landmarks related to the model's predictions, offering users a more intuitive understanding of the model’s reasoning process. Additionally, incorporating the model into an agentic pipeline, where it collaborates with external tools or agents, could significantly improve its ability to handle complex, multi-step queries in real-world applications. Furthermore, introducing a preprocessing step before the model generates responses, where a smaller model identifies the key points of the question and refines it by replacing these key points with corresponding values from the dataset, could enhance the model's accuracy and relevance in addressing user queries.

%\item Reducing the token usage requesting only the function solve and not the full import of the libraries.
%\section{Limitations and Future Work}

%During our experiments with the finetuned model, we identified several significant limitations in both the model and the dataset. Addressing these limitations is essential for enhancing the model's performance and usability. For example, when queries include coordinates (latitude and longitude) in a format different from the dataset's standard ('[lat, long]'), the model consistently fails to provide accurate or approximate answers. Additionally, the model struggles with queries that contain misspellings or alternative names for specific information, such as locations or types of crimes, that differ from those in the dataset. For instance, when asked "How many crimes occurred in Guangdong?" instead of "How many crimes occurred in Guangdong Province?", the model is unable to produce a correct response.

%\begin{itemize}
 %   \item \textbf{Dataset Improvements:} 
  %  \begin{itemize}
   %     \item Expand the range area to Brazil and NY (and possibly Lima). 
    %    \item Use the LLM-as-a-judge in the dataset construction phase.
     %   \item Scale the dataset to 10K records.
    %\end{itemize}
    %\item \textbf{Model Improvements:}
    %\begin{itemize}
     %   \item Relate the output of the model with the visualization feedback.
     %   \item Use the model as a part of Agentic pipeline
    %\end{itemize}
%\end{itemize}