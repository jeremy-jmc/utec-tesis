\lstdefinestyle{pythoncode}{
  language=Python,
  basicstyle=\tiny\ttfamily,
  backgroundcolor=\color{gray!5},
  keywordstyle=\color{blue},
  commentstyle=\color{green!50!black},
  stringstyle=\color{orange},
  numberstyle=\tiny\color{gray},
  numbers=left,
  stepnumber=1,
  numbersep=8pt,
  frame=single,
  breaklines=true,
  captionpos=b,
  showstringspaces=false,
  tabsize=4,
  baselinestretch=0.8,
  lineskip=-1pt
}
% Ajuste opcional del formato de captions
\captionsetup[lstlisting]{font=small,labelfont=bf}



\chapter{ EXPERIMENTS AND RESULTS}

This chapter presents the outcomes derived from applying the methodology detailed in the preceding chapter. We begin by specifying the hyperparameters employed during the training phase. Next, we report the results from the evaluated models, covering both quantitative and qualitative analyses. Lastly, we discuss the significance of these findings and include case studies to demonstrate the practical relevance of our results.

\section{Hyperparameters}


The selection of key hyperparameters for training was guided by empirical observation and best practices in fine-tuning large language models:

\begin{itemize}
  \item \textbf{Warmup Ratio:} We initially set the warmup ratio to 0.03; however, this led to instability during the early stages of training, with noticeable spikes in the loss. Increasing the warmup ratio to 0.05 significantly improved training stability, consistent with findings in transformer-based models such as RoBERTa, where extended warmup periods are known to facilitate smoother convergence \citep{liu2019robertarobustlyoptimizedbert}.
  \item \textbf{Weight Decay:} To mitigate overfitting and enhance generalization, especially given the relatively small size of our dataset, we applied a weight decay of 0.05. This choice aligns with established practices in training deep neural networks on limited data, where appropriate regularization is crucial for model robustness \citep{brainacgan}.
  \item \textbf{Learning Rate:} The learning rate was initially set to 2e-3, but this configuration resulted in poor convergence during training. Considering that we employed LoRA for fine-tuning the Llama model, we reduced the learning rate to $1.5e^{-4}$. This lower rate aligns with commonly adopted values for adapting pre-trained large language models using parameter-efficient techniques, and it yielded significantly improved convergence behavior \citep{zhou2024automixqselfadjustingquantizationhigh}.
\end{itemize}

The other hyperparameters (such as LoRa range and batch size) were chosen according to hardware limitations. Full detail in Table \ref{tab:hyperparameters}.

\begin{table}[hbtp]
\centering
\small
\begin{tabular}{ll}
  \toprule
  \textbf{Hyperparameter} & \textbf{Value} \\
  \midrule
  LoRA rank ($r$) & 32 \\
  LoRA alpha & 32 \\
  LoRA dropout & 0.05 \\
Batch size (per device) & 32 \\
Gradient accumulation steps & 8 \\
Max sequence length & 3,000 tokens \\
Training epochs & 7 \\
Learning rate & $1.5e^{-4}$ \\
Optimizer & \texttt{adamw\_torch\_fused} \\
Scheduler & \texttt{cosine\_with\_restarts} \\
Warmup ratio & 0.05 \\
Weight decay & 0.05 \\
Quantization & 4-bit (NF4, double quant) \\
\bottomrule
\end{tabular}
\caption{Fine-tuning Hyperparameters for ChinaCrimesQACode}
\label{tab:hyperparameters}
\end{table}

\section{Quantitative Results}
\begin{table}[hbtp]
\centering
\footnotesize
\setlength{\tabcolsep}{2pt}
\begin{tabular}{l|ccc|ccc|ccc|ccc}
\toprule
\textbf{Metric} & \multicolumn{3}{c|}{\textbf{Fine-tuned}} & \multicolumn{3}{c|}{\textbf{Base}} & \multicolumn{3}{c|}{\textbf{o4-mini}} & \multicolumn{3}{c}{\textbf{DeepSeekV3}} \\
 & \multicolumn{3}{c|}{\textbf{Llama3}} & \multicolumn{3}{c|}{\textbf{Llama3}} & \multicolumn{3}{c|}{} & \multicolumn{3}{c}{} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
 & \textbf{Mean} & \textbf{Std} & \textbf{Med} & \textbf{Mean} & \textbf{Std} & \textbf{Med} & \textbf{Mean} & \textbf{Std} & \textbf{Med} & \textbf{Mean} & \textbf{Std} & \textbf{Med} \\
 \midrule
Percent Error@k\,($\downarrow$)  & 0.089 & 0.195 & \textbf{0.000} & 0.220 & 0.315 & \textbf{0.000} & \textbf{0.003} & \textbf{0.014} & \textbf{0.000} & 0.025 & 0.060 & \textbf{0.000} \\
Pass@k\,($\uparrow$)           & \textbf{0.784} & \textbf{0.412} & \textbf{1.000} & 0.267 & 0.442 & 0.000 & 0.303 & 0.459 & 0.000 & 0.202 & 0.401 & 0.000 \\
Pass\textasciicircum k\,($\uparrow$)     & \textbf{0.581} & \textbf{0.417} & \textbf{0.667} & 0.109 & 0.235 & 0.000 & 0.063 & 0.175 & 0.000 & 0.051 & 0.161 & 0.000 \\
CodeBLEU@k\,($\uparrow$)     & \textbf{0.403} & \textbf{0.077} & \textbf{0.400} & 0.332 & 0.049 & 0.331 & 0.370 & 0.054 & 0.375 & 0.372 & 0.061 & 0.379 \\
\bottomrule
\end{tabular}
\caption{Comparison of Evaluation Metrics: Fine-tuned Llama3, Base Llama3, o4-mini, and DeepSeekV3 (Test Set)}
\label{tab:combined_metrics}
\end{table}

Table~\ref{tab:combined_metrics} reveals that our fine-tuned Llama3-8B-Instruct model achieves superior functional performance with Pass@k of 0.784 and Pass\textasciicircum k of 0.581, substantially outperforming o4-mini (0.303 and 0.063) and DeepSeekV3 (0.202 and 0.051). This demonstrates that domain-specific fine-tuning enables the model to generate semantically correct solutions for crime data analysis tasks, prioritizing analytical accuracy over syntactic perfection.

However, the fine-tuned model exhibits higher Percent Error@k (0.089) compared to o4-mini (0.003) and DeepSeekV3 (0.025), indicating more compilation errors. This apparent contradiction suggests that general-purpose models often produce syntactically correct code that compiles successfully but fails to solve the underlying problem, while our model prioritizes domain reasoning. DeepSeekV3's elevated CodeBLEU@k (0.372) reflects stylistic similarities to our training data rather than functional superiority, as evidenced by its poor Pass@k performance.

These findings underscore the decisive value of domain-specific adaptation: the base Llama3 model without fine-tuning shows severely degraded performance (Pass@k: 0.267), while our targeted approach achieves practical problem-solving capability despite compilation imperfections. Expanding the crime-domain training dataset could address the Percent Error@k gap while maintaining superior semantic understanding, demonstrating that task-specific fine-tuning is essential for specialized analytical domains.

% Based on the observed metrics in Table \ref{tab:combined_metrics}, several conclusions emerge regarding the performance of the fine-tuned Llama3‑8B‑Instruct model versus the base o4‑mini. First, Llama3‑8B‑Instruct exhibits a higher Percent Error@k than o4‑mini and DeepSeekV3; yet it significantly outperforms o4‑mini in both Pass@k and Pass\textasciicircum k. This indicates that, despite a slightly lower rate of successful compilation, the fine‑tuned model produces more precise and semantically relevant solutions. In contrast, o4‑mini's better Percent Error@k can be misleading: it often compiles code that runs but fails to solve the problem correctly.

% These findings indicate that broadening and diversifying the crime-domain dataset is essential: a richer corpus will surface edge cases, lower the 0.233 → 0.003 Percent Error@k gap, and lift Pass@k beyond its current 0.742 vs 0.303 advantage. We selected o4-mini because its balance of accuracy, cost, and speed makes it a practical deployment benchmark, yet without domain-specific fine-tuning it still trails the task-specific precision achieved by Llama3-8B-Instruct, demonstrating the decisive value of targeted data and adaptation.

% Building on the results, we conclude that expanding and diversifying the crime‑domain dataset is imperative: a broader corpus will expose edge cases, reduce Percent Error@k, and allow the model to generalize across varied spatio‑temporal crime patterns, ultimately driving all key metrics upward. We chose o4‑mini and DeepSeekV3 as our baseline because its favorable trade‑off among accuracy, computational efficiency, and cost makes it a realistic benchmark for real‑world deployment, yet the current evaluation clearly shows that without domain‑specific fine‑tuning it cannot match the task‑specific precision of Llama3‑8B‑Instruct, underscoring the decisive impact of targeted data and adaptation.

% This discrepancy is likely rooted in architectural and training differences. o4‑mini is believed to use a Mixture‑of‑Experts (MoE) setup with approximately 40B total parameters—only about 8B of which are active per inference—whereas Llama3‑8B‑Instruct is a dense model with all 8B parameters actively contributing . While MoE architectures provide access to a broader parameter pool, this capacity advantage does not automatically translate to superior domain-specific performance. In contrast, the fully fine‑tuned Llama model has internalized domain-specific patterns—such as those needed to manipulate crime data (locations, dates, crime types, etc.)—enabling it to generate more accurate and relevant code.

\section{Qualitative Analysis}

We conducted one case study to illustrate the practical applicationa of our fine-tuned model in real-world scenarios. 

% The first case focuses on counterfactual evaluation of targeted interventions in crime hotspots, while the second explores geospatial queries related to crime data.

\subsection{Case: Counterfactual Evaluation of Targeted Interventions in Crime Hotspots of Guangdong Province}

Zhongshan, a city in Guangdong with around 4.4 million residents (2020), has implemented data-driven policing strategies. Official reports show crime reductions, with a 37\% drop in serious violence and 46\% in theft and robbery by mid-2020 \cite{Zhongshan2020}, highlighting the value of analyzing its crime data for policymaking.

To validate our fine-tuned LLM's capability as an analytical assistant for crime data interpretation, we designed three counterfactual scenarios that test the model's ability to process natural-language queries and generate actionable geospatial insights \cite{William2025}. Each scenario examines different dimensions of crime prevention and resource allocation strategies.



\noindent \textbf{Scenario 1: Night-time Crime Prevention Impact Analysis}

We posed the question: ``What percentage reduction in overall crime could be achieved if all night-time crimes in Guangdong Province during 2019 were prevented?'' This scenario evaluates the potential impact of enhanced nighttime patrol strategies or improved lighting infrastructure.

The model's analytical approach demonstrates sophisticated understanding of temporal crime patterns. As shown in Listing \ref{lst:q1}, the generated code correctly filters crimes by province and year, implements proper time-based categorization (defining night-time as 6 PM to 6 AM), and calculates the proportional impact of targeted interventions.

\lstinputlisting[style=pythoncode, label={lst:q1}]{codigos/q1.py}

\begin{tcolorbox}[colback=white!95!black, colframe=black, title=Q1 Response, fontupper=\scriptsize, boxsep=2pt, left=3pt, right=3pt]
  The province of Guangdong in China reported 1376 total crimes in 2019. Out of those, 633 crimes occurred at night. If all night-time crimes were prevented, the overall crime rate would decrease by 46.00\%. This is because 46.00\% of the total crimes in 2019 were night-time crimes.
\end{tcolorbox}

The analysis revealed that Guangdong Province recorded 1,376 total crimes in 2019, with 633 occurring during nighttime hours. The model concluded that preventing all night-time crimes would achieve a 46.00\% reduction in overall crime rates, indicating that nearly half of all criminal activity occurs during vulnerable nighttime periods.


\noindent \textbf{Scenario 1 - Questions Reformulation and Responses}

\begin{table}[hbtp]
\centering
\small
\begin{tabular}{|p{0.4\textwidth}|p{0.5\textwidth}|}
\hline
\textbf{Question} & \textbf{Response} \\
\hline
If all night-time crimes in Guangdong Province were completely prevented in 2019, what percentage drop in overall crime would result? & The province of Guangdong in China reported 1376 total crimes in 2019. If all nighttime crimes were eliminated, the crime rate would decrease by 46.00\%. This is because one of the outputs directly states that the percentage decrease in total crime if all nighttime crimes were eliminated is 46.00\%.. \\
\hline
What would be the estimated percentage decrease in total crime in Guangdong Province during 2019 if night-time crimes had been entirely eliminated? & The correct approach is to calculate the percentage of nighttime crimes in relation to total crimes and then use that percentage to estimate the decrease. In this case, the percentage of nighttime crimes in 2019 ranged from 31.57\% to 46.00\% across the different outputs.

Using the highest percentage (46.00\%), if all nighttime crimes were eradicated, the estimated percentage decrease in total crime would be 46.00\% because 46.00\% of the crimes in 2019 occurred at night. \\
\hline
How much could the overall crime rate in Guangdong Province for 2019 be reduced, in percentage terms, if all night-time crimes were prevented? & The correct total number of crimes in Guangdong Province for 2019 is 1376, with 957 daytime crimes and 419 nighttime crimes. If all night-time crimes were eliminated, the crime rate would decrease by 46.00\% (because the night-time crimes account for 30.45\% of the total crimes). \\
\hline
\end{tabular}
\caption{Scenario 1 Questions Reformulation and Responses}
\label{tab:questions_responses}
\end{table}

The model's responses consistently identify a 46\% reduction in total crime if nighttime incidents were eliminated, which aligns with the original data. However, subtle issues undermine reliability: Answer 1 uses vague phrasing (``one of the outputs'') that reduces clarity; Answer 2 introduces an unsupported ``31.57\% to 46\%'' range, creating confusion; and Answer 3 incorrectly reports nighttime crime as 419 instead of 633, leading to an internally inconsistent breakdown. These inconsistencies highlight the need for the model to provide more comprehensive explanations alongside numerical results, ensuring users can understand the reasoning process and verify calculations. The variations in supporting details across different query formulations demonstrate the model's current limitations in maintaining consistent reasoning when the same question is asked in different ways, suggesting a need for more diverse training examples that focus on detailed crime temporal analysis.


\noindent \textbf{Scenario 2: Spatial Crime Diffusion Effects}  % TODO: mejorar

The second scenario examined spatial crime relationships: ``How would the total number of crimes across all counties within a 70 km radius of the point [22.516998, 113.392723] change if crime in that area were reduced by 20\%?'' This question tests the model's capacity for geospatial reasoning and understanding of crime diffusion effects.

The model's implementation, presented in Listing \ref{lst:q2}, demonstrates interesting geospatial processing capabilities. It correctly creates a buffer zone around the specified coordinates, identifies neighboring counties through geometric intersection analysis, and simulates crime reduction scenarios through statistical sampling.

\lstinputlisting[style=pythoncode, label={lst:q2}]{codigos/q2.py}

\begin{tcolorbox}[colback=white!95!black, colframe=black, title=Q2 Response, fontupper=\scriptsize, boxsep=2pt, left=3pt, right=3pt]
  The current total number of crimes in the area is 68,247. If crime in that area were reduced by 20\%, the new total would be approximately 54,598. This means about 13,649 crimes would be reduced.
\end{tcolorbox}

This result indicates a direct spatial spillover effect: a 20\% reduction in crime at the central location leads to an equivalent 20\% decrease in total crimes across the surrounding area. Specifically, the model predicts a drop from 68,247 incidents to 54,598, a reduction of 13,649 crimes, demonstrating a proportional relationship between crime reduction at the focal point and its adjacent counties.

\noindent \textbf{Scenario 2 - Questions Reformulation and Responses}
\begin{table}[hbtp]
\centering
\small
\begin{tabular}{|p{0.4\textwidth}|p{0.5\textwidth}|}
\hline
\textbf{Question} & \textbf{Response} \\
\hline
What impact would a 20\% reduction in crime at [22.516998, 113.392723] have on the combined crime count for all counties within a 70 km radius? & The current total crime count in the 70 km radius is 68,247. If there's a 20\% reduction in crime, the new total crime count would be 54,598. This reduction would affect all 331 counties within the 70 km radius. \\
\hline
 By how much would the total crimes across all counties within 70 km of [22.516998, 113.392723] decrease if crime in that zone dropped by 20\%? & Not possible to answer. \\
\hline
What would be the decrease in overall crime across all counties within 70 km of [22.516998, 113.392723] if crime at that central point fell by 20\%? & 
The crime count within 70 km of the specified location is currently 68,247. If crime at that central point decreased by 20\%, it would drop to 54,598. This means there would be a 20\% decrease in crime.

This is because the current average crime rate of 206.18 crimes per county decreased by 20.00\%. \\
\hline
\end{tabular}
\caption{Scenario 2 Questions Reformulation and Responses}
\label{tab:questions_responses_2}
\end{table}

The review of the responses shows that the initial count of 68,247 crimes within a 70 km radius of [22.516998, 113.392723], when a 20\% reduction is applied at the central point, becomes 54,598 crimes (13,649 fewer incidents). This calculation remains consistent across the reformulated questions, except for the only one case in which the model was unable to make a coherent answer.


\noindent \textbf{Scenario 3: Reporting Rate Impact on Safety Rankings}

The final scenario explored data quality implications: ``Considering the top 10 safest counties in Guangdong Province, how would this ranking change if crime reporting increased by 15\% in Zhongshan City in 2019?'' This question examines how improved reporting mechanisms might alter safety assessments.

The model's approach, illustrated in Listing \ref{lst:q3}, systematically ranks counties by crime frequency, simulates increased reporting rates, and evaluates ranking changes. The analysis revealed that despite a 15\% increase in reported crimes (from 80 to 92 incidents), Zhongshan City maintained its fourth position among the safest counties.

\lstinputlisting[style=pythoncode, label={lst:q3}]{codigos/q3.py}

\begin{tcolorbox}[colback=white!95!black, colframe=black, title=Q3 Response, fontupper=\scriptsize, boxsep=2pt, left=3pt, right=3pt]
  Based on the provided code outputs, the current top 10 safest counties in Guangdong Province for 2019 are:

  1. Bao'an District with 298 crimes

  2. Dongguan City with 139 crimes
  
  3. Baiyun District with 113 crimes
  
  4. Zhongshan City with 80 crimes
  
  5. Longgang District with 78 crimes
  
  6. Panyu District with 62 crimes
  
  7. Shunde District with 61 crimes
  
  8. Chancheng District with 56 crimes
  
  9. Nanshan District with 55 crimes
  
  10. Haizhu District with 49 crimes

  If the crime reporting in Zhongshan City increased by 15\% in 2019, the new top 10 safest counties would be:

  1. Bao'an District with 298 crimes

  2. Dongguan City with 139 crimes

  3. Baiyun District with 113 crimes

  4. Zhongshan City with 92 crimes (after 15\% increase)

  5. Longgang District with 78 crimes

  6. Panyu District with 62 crimes

  7. Shunde District with 61 crimes

  8. Chancheng District with 56 crimes

  9. Nanshan District with 55 crimes

  10. Haizhu District with 49 crimes

  The change in ranking is due to Zhongshan City moving from 4th to 4th place after the increase in crimes.
\end{tcolorbox}


\noindent \textbf{Scenario 3 - Questions Reformulation and Responses}

\begin{table}[hbtp]
\centering
\small
\begin{tabular}{|p{0.4\textwidth}|p{0.5\textwidth}|}
\hline
\textbf{Question} & \textbf{Response} \\
\hline
How would a 15\% increase in crime reporting in Zhongshan City during 2019 impact the rankings of the top 10 safest counties in Guangdong Province? & Zhongshan City would remain in 4th place despite the increase in reported crimes. \\
\hline
If crime reporting in Zhongshan City had increased by 15\% in 2019, what impact would that have on the ranking of the top 10 safest counties in Guangdong Province? &The code calculates the adjusted crime counts for each county with a 15\% increase but encounters errors when trying to analyze Zhongshan City's data (which is 0 crimes in all cases). As a result, the adjusted rankings remain identical to the original rankings.. \\
\hline
In the context of the top 10 safest counties in Guangdong Province, what changes would occur in the rankings if Zhongshan City's crime reports rose by 15\% in 2019? & Not possible to answer. \\
\hline
\end{tabular}
\caption{Scenario 3 Questions Reformulation and Responses}
\label{tab:questions_responses_3}
\end{table}

The model's Scenario 3 responses exhibit varied relevance and task completion: only the first answer correctly states that Zhongshan would stay fourth after a 15\% crime increase, directly addressing the ranking impact, while the second and third responses either fabricate data errors or refuse to answer, thus failing task completion.


\noindent \textbf{Analytical Implications and Future Potential}

These case studies demonstrate the model's practical utility despite the quantitative metrics presented in Table \ref{tab:combined_metrics}. While our fine-tuned Llama3 model shows room for improvement in compilation success rates, the generated code consistently exhibits interesting capabilities in data filtering, temporal analysis, geospatial processing, and statistical simulation, all essential for crime data analysis.

The qualitative analysis reveals that even with current limitations, the model successfully transforms complex criminological questions into executable analytical workflows with contextually appropriate interpretations. This bridges the gap between technical analysis and policy-relevant insights, enabling law enforcement agencies to make informed decisions about resource allocation and intervention strategies.

These promising results suggest that with continued refinement, particularly through expanded domain-specific datasets and targeted improvements to reduce compilation errors, our approach could become a valuable tool for evidence-based policing initiatives. The counterfactual analysis framework validates the potential of fine-tuned LLMs for supporting data-driven decision-making in public safety contexts.


\section{Final considerations}

This chapter evaluated our fine-tuned Llama3-8B-Instruct model for crime data analysis, demonstrating that despite higher compilation error rates compared to o4-mini (Percent Error@k: 0.233 vs 0.003), the model significantly outperformed in solution accuracy (Pass@k: 0.742 vs 0.303), indicating superior semantic understanding of crime-related queries. Through three scenarios analyzing Guangdong Province crime data, we validated the model's practical utility for evidence-based policing, revealing that night-time crime prevention could reduce overall crime by 46\%, spatial interventions produce significant spillover effects (13 649 crime reduction from a 20\% reduction at a central point), and safety rankings remain stable despite improved reporting rates. The results confirm that fine-tuned LLMs can effectively bridge technical data analysis with policy-relevant insights, though expanding the domain-specific dataset remains crucial for reducing compilation errors and enhancing generalization across varied crime patterns.

