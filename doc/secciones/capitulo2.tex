\chapter{ STATE OF THE ART}

% TODO: introduction

\section{Large-Language Models for Urban Scenarios}

Recent advances show that LLMs are increasingly being adapted to address urban computing tasks. Three recent approaches illustrate how these models can be used for both forecasting urban phenomena and orchestrating multiple models to tackle complex urban tasks.

\cite{Li2024UrbanGPT} proposes UrbanGPT, a spatio-temporal LLM for forecasting urban dynamics such as traffic flows and crime rates. The model receives spatial and time series information through the prompt, then employs a spatio-temporal dependency encoder and a lightweight alignment module to project these representations into the LLM's latent space, achieving performance on par with or surpassing state-of-the-art models in multiple datasets. 

Complementing this, \cite{Jiang2024UrbanLLM} leverage the agentic capabilities of LLMs to decompose urban-related queries into structured sub-tasks (e.g., forecasting, anomaly detection, POI recommendation, etc). This approach, termed UrbanLLM, assigns each sub-task to a specialised model from a curated model zoo, and integrates the results into a unified response.


Recent research from Google has explored the use of foundation models for geospatial reasoning \cite{2025GoogleGeospatialReasoning}. It introduces an agentic workflow powered by Gemini to assist users in tasks such as visualizing pre and post disaster scenarios or conducting damage assessments. Their approach integrates diverse modalities: maps, weather data, and satellite imagery, and highlights the need for foundation models capable of aligning heterogeneous spatial information . Together with UrbanGPT's forecasting focus and UrbanLLM's model orchestration, this work reflects a growing trend toward multimodal LLM-driven systems for urban scale analysis and decision making.

Another study from Google introduces Visual Chronicles \cite{Deng2025VisualChronicles}, a multimodal LLM-based system designed to identify and describe frequently occurring visual changes across urban environments using a dataset provided by Google Street View imagery. It leverages a vast collection of geolocated, timestamped images to identify trends without requiring labeled training data. To overcome the limitations of MLLMs in processing such massive datasets, the authors design a scalable pipeline that enables efficient retrieval, comparison, and semantic analysis of visual patterns across both space and time.
% \cite{Deng2025VisualChronicles} highlight the system's ability to uncover temporal patterns using MLLMs, capitalizing on their open-ended semantic understanding capabilities. Given that the datasets are several orders of magnitude too large for an MLLM to process as context, the system employs innovative techniques to manage and analyze the data effectively.

% There are more LLMs on Urban Applications: See UrbanLLM paper
% \cite{Zhang2023GeoGPT}


\section{Large-Language Models for Coding-Tasks}

Large language models such as Llama 3 \cite{Grattafiori2024Llama3} already display substantial, general-purpose coding, instruction-following and reasoning skills \cite{Grattafiori2024Llama3}. In addition, a wave of code-specialised models—e.g., Seed-Coder, OpenCodeReasoning, Qwen 2.5-Coder, NuminaMath-7B-TIR, and Code Llama—pushes state-of-the-art accuracy on competitive-programming, software-engineering benchmarks, and mathematical problem solving using Python code \cite{Seed2025SeedCoder, Ahmad2025OCRNVidia, Hui2024Qwen25Coder, Roziere2024CodeLlama, Moshkov2025AIMO2, Yin2024MuMathCode, Gou2024ToRA}. These models are constantly improved and frequently surpassed by even newer architectures, reflecting the rapid pace of progress in this area.

Despite the rapid progress in LLMs for code generation, the availability of standardized benchmarks specifically tailored to data science tasks remains limited. Only a handful of recent datasets address this gap: for example, DS‑1000 \cite{Lai2022DS1000} defines 1,000 realistic Python data-analysis problems (with Pandas, NumPy, etc.) collected from StackOverflow, and DataSciBench \cite{Zhang2025DataSciBench} is a recently published comprehensive LLM benchmark covering diverse data-science tasks with an innovative framework of evaluation.

In contrast, the text-to-SQL domain (closely related to data analysis) has more established benchmarks and model work. For example, \cite{Dominguez2024BlarSQL} demonstrated that fine-tuned Llama2 and Code Llama models can decompose database queries and achieve SQL accuracy comparable to GPT-4 on natural-language-to-SQL tasks. Similarly, Snowflake's Arctic-Text2SQL model \cite{Yao2025ArcticText2SQLR1}, trained with reinforcement learning and comprising 7B parameters, achieves state-of-the-art execution accuracy across six standard NL2SQL benchmarks, and currently holds the top single-model position on the BIRD leaderboard \cite{Li2023BirdSQL}.

Most widely used Text2SQL benchmarks, such as BIRD and Spider, are limited to a single SQL dialect and lack support for geospatial operations, including buffer queries and interactions with polygon data types \cite{Li2023BirdSQL, Yu2019Spider}. To address these limitations, this thesis adopts a different approach: instead of relying on SQL, the LLM is used to generate Python code that primarily utilizes the `pandas` and `geopandas` libraries. This strategy avoids SQL dialect constraints and leverages the LLM's strengths in code generation.

% \section{RAG Techniques for Complex Data}

% % * Introduction
% Retrieval-Augmented Generation (RAG) frameworks aim to enhance LLMs by integrating external sources of knowledge, such as structured databases, time series, or knowledge graphs. Recent research has extended RAG beyond textual documents to support spatial, temporal, and graph-based data retrieval.

% % * Spatial RAG
% \cite{Yu2025SpatialRAG} extends RAG to spatial tasks by integrating sparse spatial retrieval (SQL-based queries) with dense semantic retrieval (LLM-based similarity). Their method introduces three preprocessing steps to help the LLM generate complete and executable SQL queries, addressing its limitations in query formulation.
% % , addressing the common challenge of LLMs struggling to construct such queries directly from user input.

% % * RAG on temporal data
% In the temporal domain, \cite{Yang2024TimeRAG} apply RAG to the context of time series forecasting using Dynamic-Time Warping (DTW) as a distance metric to retrieve similar waveforms and trends, given a time serie as a query. The retrieved information is then utilized to improve the LLM forecasting accuracy. 

% % * RAG on graphs
% Other works, combine RAG techniques and hybrid approaches to address question-answering over textual knowledge graphs. One such example is \cite{He2024GRetriever}, who introduce G-Retriever, a flexible QA framework for knowledge graphs that incorporates a RAG into its pipeline. The framework separates node entities and edge information into two distinct embedding spaces. Using cosine similarity, it retrieves the most relevant nodes and edges for the query and reconstructs the subgraph using the Prize-Collecting Steiner Tree (PCST) algorithm. The final answer is generated by a hybrid GNN-LLM, which processes the retrieved subgraph both as text in the query prompt and through a graph encoder aligned with the LLM's token space.

% Building on this idea of graph-based retrieval, \cite{Hu2024GRAG} map textual subgraphs directly to an embedding space, allowing for the retrieval of relevant subgraphs based on their semantic similarity to the query. Then applied techniques to merging and pruning the retrieved subgraphs to improve the quality of the final answer. 

% Recent work from \cite{Guo2024LightRAG} propose LightRAG, a fully prompt-driven framework that extracts knowledge graphs, generates keywords at multiple granularities, retrieves from both vector and graph indexes, and supports fast incremental updates.

% % TODO: \cite{Edge2025GraphRAG}
% % \cite{Xiao2024TimeRAG}
% % \cite{Chen2025KGRAGSurvey}



\section{Open Crime Datasets}

Among the most popular datasets for crime analysis are the Chicago Crime dataset \cite{ChicagoDataset} and the New York City Crime dataset \cite{NYCDataset}. These datasets contain detailed records of reported crimes, including information on the type of crime, location, time, and other relevant attributes. They have been widely used in various research studies and applications related to crime prediction, analysis, and visualization.

Beyond the United States, similar efforts have been made in Latin America. In Brazil, for example, crime datasets are made publicly available at the state level through open data platforms. These resources have supported a range of research projects, including \cite{Garcia2022CriPAV} and \cite{Waqar2025CrimePredictionGNN}, which process and analyze regional crime patterns or develop predictive models.

More recently, large-scale initiatives have emerged in Asia. \cite{Zhang2025CrimeDatasetChina} introduces a large-scale crime dataset from China, comprising approximately 1 million records. The dataset spans 31 provincial-level administrative regions, 222 city-level divisions, and 548 county (district)-level jurisdictions across mainland China. Unlike the structured records in the aforementioned datasets, this resource was constructed by extracting crime information from unstructured judicial documents using LLMs, enabling broader geographic and semantic coverage. Additionally, it includes detailed fields such as case descriptions, victim and defendant information, and final judgments, offering more possibilities for anlysis and research.



\section{Crime-Data Visualization Tools}

In the context of crime data analysis, several visualization systems have been proposed to support pattern recognition, hotspot identification, and urban context interpretation. These tools typically integrate geospatial data with interactive visual analytics techniques to assist expert users in understanding complex crime patterns.

Early tools like CrimeVis \cite{Silva2017CrimeVisAI}, focused on interactive exploration accross police districts (DPs) brushing-and-linking techniques. Later systems extended this groundwork by incorporating advanced feature engineering and machine learning techniques. CrimAnalyzer \cite{Garcia2021CrimAnalyzer} proposed a Non-negative Matrix Factorization (NMF) based technique to identify hostpots. Furthermore, CriPAV \cite{Garcia2022CriPAV} incorporates autoencoders to embed and cluster hotspots, facilitating the analysis of the relationship between crime and urban features.


% \cite{Garcia2021CrimAnalyzer} propose CrimAnalyzer, that relies on Non-negative Matrix Factorization (NMF) to identify hostpots.
% \cite{Garcia2022CriPAV} propose CriPAV a visualization system to assist experts to figure out the relation between crime and urban features, using autoencoders to generate embeddings of hotspots to cluster them. 


% TODO Include: \cite{Garcia2020MiranteAV} introduces Mirante, a crime mapping visualization system that allows pattern analysis in a street-level scale.
% \cite{Salah2022BigCDVis} 



\section{NLP in Data Visualization}

Eviza \cite{Setlur2016Eviza} convert natural language input to filters applied to visualizations. 

\cite{Setlur2016Eviza} introduces Eviza, a natural language interface for visual data analysis, leveraging a probabilistic grammar-based approach with predefined syntactic rules. The system incorporates a template-based autocompletion feature to provide users with contextual suggestions, enabling an interactive conversation with existing visualizations. Tested on geographic datasets, such as earthquake data in the US, the interface enhances user interaction by implementing language pragmatics through a finite state machine. However, Eviza faced challenges in recognizing all parts of long and complex queries and struggled with certain grammatical constructs, highlighting the need for more robust natural language processing techniques in visualization systems.


\cite{Wu2024LLMVis}


Early research on natural language interfaces for data visualization has explored how users can interact with visual content through conversational input.

\cite{Liu2024NLDriven} introduce a framework for controlling data visualizations through natural language. Their approach centers on two key components: a natural language-to-task translator and a visualization manipulation parser. The translator, based on a fine-tuned T5 model, maps user queries into a hierarchical structure of tasks, which are then interpreted to apply manipulation operations over existing visualizations.


\cite{Luo2022NL2Vis}

\cite{Narechania2021NL4DV}

\cite{Liu2021ADVISor}

\cite{Silva2017CrimeVisAI}

% \section{KGQA Datasets}
% ExplaGraphs, WebQSP, SceneGraphs


% \section{Question Answering on Knowledge Graphs}
% \cite{Dai2024QASTKG}


% \section{GNN-LLM}
% \cite{He2024GRetriever}, \cite{Perozzi2024GraphToken}, \cite{Fatemi2023GraphEncoding}


% ? DL-based crime prediction encounters significant obstacles, such as concerns about fairness, accountability, transparency, interpretability, security, and privacy \cite{Ersoz2025CrimePredictionXAISurvey}.
% ? Inexeperienced users have difficulties using database query languages like SQL to express their data needs \cite{Setlur2016Eviza}. 
% ? Natural language can be ambiguous due to syntactic and semantic variations between the user's mental model and the system's mental model \cite{Setlur2016Eviza}.
% ? Large reasoning models, suchas as Qwen-QwQ and DeepSeek-R1 have demostraded impressive stepwise reasoning capabilities over long sequences through large-scale reinforcement learning \cite{Wu2025AgenticReasoning}
